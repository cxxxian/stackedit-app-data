![输入图片说明](/imgs/2025-02-20/9TZD0p2ONh163QNC.png)

![输入图片说明](/imgs/2025-02-20/Y78LYgrwZb33YKib.png)

![输入图片说明](/imgs/2025-02-20/TAyiJxyE2WadK0bT.png)

![输入图片说明](/imgs/2025-02-20/VRLJieiky9cBwbGu.png)

由于法线是用`xyz`构成的，所以我们可以把法线存入图片，就像颜色贴图`rgb`一样
然后进行法线与`rgb`转换

![输入图片说明](/imgs/2025-02-20/FZTo67buQqfcHFvz.png)

# 代码实验
## 1.新建一个带有法线贴图的材质（从Phong改过来）
### 1.1创建材质
创建`phongNormalMaterial.h`，并声明一个纹理贴图用作法线贴图`mNormalMap`
```cpp
#pragma once
#include "../material.h"
#include "../../texture.h"

class PhongNormalMaterial :public Material {
public:
	PhongNormalMaterial();
	~PhongNormalMaterial();

public:
	Texture*	mDiffuse{ nullptr };
	Texture*	mSpecularMask{ nullptr };

	Texture*	mNormalMap{ nullptr };
	float		mShiness{ 1.0f };
};
```
并且去`material.h`添加相应枚举
```cpp
enum class MaterialType {
	...
	PhongNormalMaterial
};
```

### 1.2创建shader
从`phong.vert`和`phong.frag`复制过来，创建`phongNormal.vert`和`phongNormal.frag`
`phongNormal.vert`无需做修改，因为它和法线没啥关系
`phongNormal.frag`中，可以看到我们原本传入`calculateDirectionalLight`方法中的参数`normalN`，是根据`shader`中的顶点插值得出的
现在我们希望用上自己的法线贴图
利用纹理采样的得到`rgb`值，然后将`0~1`转化为`-1~1`
最后归一化即可得到`normalN`进行使用
```glsl
uniform sampler2D normalMapSampler;
void main()
{
	...
	//计算光照的通用数据
	//vec3 normalN = normalize(normal);
	vec3 normalN = texture(normalMapSampler, uv).rgb;
	normalN = normalN * 2.0 - vec3(1.0);//从0~1变成-1~1
	normalN = normalize(normalN);
	
	vec3 viewDir = normalize(worldPosition - cameraPosition);

	result += calculateDirectionalLight(objectColor, directionalLight,normalN, viewDir);
	...
}
```
### 1.3renderer中修改（pickShader，renderObject）
在`render.h`中声明一个`shader`对象
```cpp
private:
	...
	Shader* mPhongNormalShader{ nullptr };
```
到`render.cpp`中进行初始化
```cpp
Renderer::Renderer() {
	...
	mPhongNormalShader = new Shader("assets/shaders/advanced/phongNormal.vert", "assets/shaders/advanced/phongNormal.frag");
}
```
到`pickShader`方法中完善
```cpp
Shader* Renderer::pickShader(MaterialType type) {
	Shader* result = nullptr;

	switch (type) {
		...
	case MaterialType::PhongNormalMaterial:
		result = mPhongNormalShader;
		break;
	...
	}
	return result;
}
```
最后去到`renderObject`方法中添加相应的`case`
和`phongMaterial`没有什么区别，只是要多传输一个法线贴图
```cpp
case MaterialType::PhongNormalMaterial: {
	PhongNormalMaterial* phongMat = (PhongNormalMaterial*)material;

	//diffuse贴图帧更新
	//将纹理采样器与纹理单元进行挂钩
	shader->setInt("sampler", 0);
	//将纹理与纹理单元进行挂钩
	phongMat->mDiffuse->bind();
	
	//法线贴图
	shader->setInt("normalMapSampler", 1);
	phongMat->mNormalMap->bind();
	...
}
	break;
```

## 2.创建一个平面，使用法线贴图纹理
创建一个平面，
我们还是采用双`pass`渲染
```cpp
void prepare() {
	...
	//pass 01
	auto planeGeo = Geometry::createPlane(5, 5);
	auto planeMat = new PhongNormalMaterial();
	planeMat->mDiffuse = new Texture("assets/textures/normal/brickwall.jpg", 0, GL_SRGB_ALPHA);
	planeMat->mNormalMap = new Texture("assets/textures/normal/normal_map.png", 1);
	planeMat->mShiness = 32; //光斑大小
	auto planeMesh = new Mesh(planeGeo, planeMat);
	sceneOff->addChild(planeMesh);

	//pass 02
	auto sgeo = Geometry::createScreenPlane();
	auto smat = new ScreenMaterial();
	smat->mScreenTexture = fbo->mColorAttachment;
	//smat->mScreenTexture = new Texture("assets/textures/wall.jpg", 0, GL_SRGB_ALPHA);
	auto smesh = new Mesh(sgeo, smat);
	scene->addChild(smesh);
	...
}
```
用上法线贴图后真实了很多

![输入图片说明](/imgs/2025-02-20/gNADZ2bXwwC0CNpf.png)

我们做一个实验，现在的平面是朝向`+z`轴的，我们的法线贴图也是朝向`+z`轴的，现在把平面放倒朝向`+y`轴，平行光也调整过来直射`-y`方向
运行会发现黑不拉几的

![输入图片说明](/imgs/2025-02-20/ID06XQjrdqfhKr7j.png)

# TBN
## TBN向量空间介绍

![输入图片说明](/imgs/2025-02-20/e1rym9JyiOARUogc.png)

![输入图片说明](/imgs/2025-02-20/pp0qragApJbbKHXB.png)

其实就是法线的坐标通过`TBN`表示出来，
然后我们只需要求的`T`和`B`就可以把法线坐标转化到世界坐标系下，`N`其实就是三角形面片的三个点的法线向量相加除`3`
法线的世界坐标 = `TBN`组成的矩阵 * `n`（`n`是法线在`TBN`坐标系下的坐标）
`TBN`组成的矩阵可以通过由`T`，`B`，`N`三个列向量组成矩阵得到
## TBN向量计算方法
解释一下这个示例图，我们构建的`TB`坐标系，不是随便构建的，比如`u1`是`0.6`，那么在T方向上u1作垂线就得在`60%`上，其他坐标同理

![输入图片说明](/imgs/2025-02-20/CIvwfmz2hlfMdFyW.png)

![输入图片说明](/imgs/2025-02-20/AWyL45zitN3Dwy6d.png)

此时我们就把`TB`矩阵表示出来了，所以重点就是等式左边那坨怎么求
`E`的部分很好求，其实就是两个坐标相减得出的向量
所以`E1 = (u2, v2) - (u1, v1)`
所以现在主要工作在于求逆矩阵

![输入图片说明](/imgs/2025-02-20/fH6uiaStGj2TXb3L.png)

![输入图片说明](/imgs/2025-02-20/B49hR8NEOfgjQ1hY.png)

![输入图片说明](/imgs/2025-02-20/g1Q3ajh5OijkoqzY.png)

![输入图片说明](/imgs/2025-02-20/effPECC4unYRfaDD.png)

`T`要乘上`ModelMatrix`是因为当模型变换时`T`也要跟随变换，
而`N`不能直接乘`ModelMatrix`是因为，我们之前有做过，当一个球体比如沿着`x`缩小时，`N`并不会保持垂直缩小，所以我们要专门计算一个`NormalMatrix`（以前推到过）
最后`B`当然就可以直接通过`TN`的叉乘得到
通过以上计算就可以得到`TBN`矩阵
 
 ## 构建TBN矩阵实验
 ### 1.Geometry类，加入带tangent（切线）的构造函数（tangent作为顶点属性）
 在`geometry.h`中加入`mTangentVbo`以及一个带`tangent`的构造函数
```cpp
private:
	GLuint mTangentVbo{ 0 };

public:
	Geometry(
	const std::vector<float>& positions,
	const std::vector<float>& normals,
	const std::vector<float>& uvs,
	const std::vector<unsigned int>& indices,
	const std::vector<float>& tangents
);
```
在`geometry.cpp`中实现如下，其他的都和原来一样，只是加入了关于`mTangentVbo`的创建以及有关`vao`的使用
解释一下这里的`&`符号：`&` 用于避免复制数据，并且提高效率，`const` 确保数据在函数中是只读的。
好处是：
**性能**：避免了复制大数据结构（如向量）的开销。
**内存效率**：不需要创建数据的副本，节省内存。
```cpp
Geometry::Geometry(
	const std::vector<float>& positions,
	const std::vector<float>& normals,
	const std::vector<float>& uvs,
	const std::vector<unsigned int>& indices,
	const std::vector<float>& tangents
) {
	...
	glGenBuffers(1, &mTangentVbo);
	glBindBuffer(GL_ARRAY_BUFFER, mTangentVbo);
	glBufferData(GL_ARRAY_BUFFER, tangents.size() * sizeof(float), tangents.data(), GL_STATIC_DRAW);
	...

	glBindBuffer(GL_ARRAY_ BUFFER, mTangentVbo);
	glEnableVertexAttribArray(3);
	glVertexAttribPointer(3, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 3, (void*)0);
	...
}
```

 ### 2.修改PhongNormalShader，加入tangent相关计算
 ![输入图片说明](/imgs/2025-02-20/sv0j4mJOcf3smk5T.png)

先明确，我们现在构造的是简单几何的情况，比如平面的每一个点的法线的朝向都是一样的，
但是球体就不一样了，球体的顶点的法线方向会受到和它连接的三角面片的影响，是所有和它连接的三角面片共同作用影响的

所以我们这次制作简单情况的话，即平面的情况
那么它的`n`就是`normal =  normalMatrix * aNormal;`
然后`tangent`（`T`）又与`normal`（`N`）垂直，可以通过叉乘算出`bitangent`（也就是`B`）
但是这里问题来了，`normalMatrix * aNormal`没问题
但是`modelMatrix * aTangent`就有问题了，因为`aTangent`是三维向量，`modelMatrix`是四维矩阵。
把`modelMatrix`降维即可：`mat3(modelMatrix)`
因为我们原本把`TBN`做成三维就是因为它不用考虑平移情况，而`modelMatrix`第四维的情况就是用来处理平移的，所以直接降维不管即可

所以在`phongNormal.vert`做如下修改
```glsl
...
layout (location = 2) in vec3 aNormal;
layout (location = 3) in vec3 aTangent;

...
out mat3 tbn;
...
void main()
{
	...
	normal =  normalMatrix * aNormal;
	vec3 tangent = normalize(mat3(modelMatrix) * aTangent);
	vec3 bitangent = normalize(cross(normal, tangent));
	tbn = mat3(tangent, bitangent, normal);
}
```
所以这样我们就算出来`tbn`矩阵了，准备传给`frag`处理
去到`phongNormal.vert`做如下修改
通过`in mat3 tbn`接收到`vert`传过来的矩阵，
将`normalN = normalize(tbn * normalN)`我们就可以得到世界坐标系下的法线了
```glsl
...
in mat3 tbn;
...
void main()
{
//环境光计算
	...
	vec3 normalN = texture(normalMapSampler, uv).rgb;
	normalN = normalN * 2.0 - vec3(1.0);//从0~1变成-1~1
	normalN = normalize(tbn * normalN);
	...
}
```
 ### 3.prepare函数中，准备实验数据与环境
 我们以前使用`geometry`直接生成一个几何体，但是这样我们拿不到里面的顶点啊什么的七七八八的数据。
 所以我们临时在`prepare`中创建一个几何体用来实验
 解释一下下面的，`positions`，`uvs`，`normals`，`indices`都没啥好奇怪的，正常声明，声明完的平面长这样（自己盘一下坐标就明白了）：
 
![输入图片说明](/imgs/2025-02-20/TzI3cJPAwg5vtyEp.png)
 
 然后下面的tangent计算，是根据公式：
 
![输入图片说明](/imgs/2025-02-20/wUvv2iMGsYQm2KRk.png)

我们只关心`T`，`B`不管
计算完`T`之后用数组存储，然后调用我们先前设计的带有`tangent`参数的`geometry`构造函数
```cpp
 void prepare() {
		...

	//pass 01
	float halfW = 2.5f, halfH = 3.5f;
	std::vector<float> positions = {
		-halfW, -halfH, 0.0f,
		halfW, -halfH, 0.0f,
		halfW, halfH, 0.0f,
		-halfW, halfH, 0.0f,
	};

	std::vector<float> uvs = {
		0.0f, 0.0f,
		1.0f, 0.0f,
		1.0f, 1.0f,
		0.0f, 1.0f
	};

	std::vector<float> normals = {
		0.0f, 0.0f, 1.0f,
		0.0f, 0.0f, 1.0f,
		0.0f, 0.0f, 1.0f,
		0.0f, 0.0f, 1.0f,
	};

	std::vector<unsigned int> indices = {
		0, 1, 2,
		2, 3, 0
	};

	//计算tangents
	std::vector<float> tangents = {};
	//位置
	glm::vec3 pos1(positions[0], positions[1], positions[2]);
	glm::vec3 pos2(positions[3], positions[4], positions[5]);
	glm::vec3 pos3(positions[6], positions[7], positions[8]);
	//uv
	glm::vec2 uv1(uvs[0], uvs[1]);
	glm::vec2 uv2(uvs[2], uvs[3]);
	glm::vec2 uv3(uvs[4], uvs[5]);

	glm::vec3 e1 = pos2 - pos1;
	glm::vec3 e2 = pos3 - pos2;

	glm::vec2 dUV1 = uv2 - uv1;
	glm::vec2 dUV2 = uv3 - uv2;

	float f = 1.0f / (dUV1.x * dUV2.y - dUV2.x * dUV1.y);

	glm::vec3 tangent;
	tangent.x = f * (dUV2.y * e1.x - dUV1.y * e2.x);
	tangent.y = f * (dUV2.y * e1.y - dUV1.y * e2.y);
	tangent.z = f * (dUV2.y * e1.z - dUV1.y * e2.z);

	for (int i = 0; i < 4; i++) {
		tangents.push_back(tangent.x);
		tangents.push_back(tangent.y);
		tangents.push_back(tangent.z);
	}

	auto planeGeo = new Geometry(positions, normals, uvs, indices, tangents);
	auto planeMat = new PhongNormalMaterial();
	planeMat->mDiffuse = new Texture("assets/textures/normal/brickwall.jpg", 0, GL_SRGB_ALPHA);
	planeMat->mNormalMap = new Texture("assets/textures/normal/normal_map.png", 1);
	planeMat->mShiness = 32;
	auto mesh = new Mesh(planeGeo, planeMat);
	mesh->rotateX(-90.0f);
	sceneOff->addChild(mesh);
	...
	dirLight->mDirection = glm::vec3(0.0f, -1.0f, 0.0f);
	...

}
```
然后我们把平面旋转，平行光也旋转一下，发现没有问题，很完美

![输入图片说明](/imgs/2025-02-20/9A01xC37jIqbYCUg.png)
 
 ### 4.计算tangent向量，并且作为attribute加入到Geometry构造当中
理解一下对于复杂几何体的情况
例如下图这种几何体，在顶点上的法向量`N`，会被它周围几个平面共同作用影响，所以就不会完全垂直于哪一个平面，
**`N`不会完全垂直于哪一个平面**！所以就会引入切线由于`N`不垂直，不垂直我们就不发构建坐标系了
 
![输入图片说明](/imgs/2025-02-23/3o9vHZCdIhqDInb0.png)

此时我们要对切线`T`进行妥协，调整`T`到与`N`垂直，即正交化
所以此时正交化得到的`T`**确实就不是原平面真正的切线**了

![输入图片说明](/imgs/2025-02-23/h6QRC78ARtu5v72U.png)

而对于几个不同平面共享的一个顶点，我们会有好几个不同的切线`T`（因为有好几个平面嘛），而对于一个顶点

![输入图片说明](/imgs/2025-02-23/rjXfWbJwJywdaAC0.png)
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTA3MTEzMjQxMCwyMDY2OTI0ODU4LDE3OD
M2NzI1OTcsMjEzODk1ODQ3LDIxMDYwMzQ2MDUsMTMyMzk5ODk0
MCwtMTMyNDYxMDMwNCwxMDg5MDU0MjYzLC0xNDUyNTEwNjU0LD
EzMjU1NjczMDgsLTE3ODgyMzg2NSwxNTk0ODA1MTcsLTEyNzY5
ODgxNTEsLTUyMDQ4Mzk2LDE1NjIxNzI5NDIsLTY4MDY2ODM4MC
wxNTQwODkwOTMzLDgwMTQxNDQyMF19
-->