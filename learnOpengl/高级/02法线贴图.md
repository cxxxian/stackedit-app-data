![输入图片说明](/imgs/2025-02-20/9TZD0p2ONh163QNC.png)

![输入图片说明](/imgs/2025-02-20/Y78LYgrwZb33YKib.png)

![输入图片说明](/imgs/2025-02-20/TAyiJxyE2WadK0bT.png)

![输入图片说明](/imgs/2025-02-20/VRLJieiky9cBwbGu.png)

由于法线是用`xyz`构成的，所以我们可以把法线存入图片，就像颜色贴图`rgb`一样
然后进行法线与`rgb`转换

![输入图片说明](/imgs/2025-02-20/FZTo67buQqfcHFvz.png)

# 代码实验
## 1.新建一个带有法线贴图的材质（从Phong改过来）
### 1.1创建材质
创建`phongNormalMaterial.h`，并声明一个纹理贴图用作法线贴图`mNormalMap`
```cpp
#pragma once
#include "../material.h"
#include "../../texture.h"

class PhongNormalMaterial :public Material {
public:
	PhongNormalMaterial();
	~PhongNormalMaterial();

public:
	Texture*	mDiffuse{ nullptr };
	Texture*	mSpecularMask{ nullptr };

	Texture*	mNormalMap{ nullptr };
	float		mShiness{ 1.0f };
};
```
并且去`material.h`添加相应枚举
```cpp
enum class MaterialType {
	...
	PhongNormalMaterial
};
```

### 1.2创建shader
从`phong.vert`和`phong.frag`复制过来，创建`phongNormal.vert`和`phongNormal.frag`
`phongNormal.vert`无需做修改，因为它和法线没啥关系
`phongNormal.frag`中，可以看到我们原本传入`calculateDirectionalLight`方法中的参数`normalN`，是根据`shader`中的顶点插值得出的
现在我们希望用上自己的法线贴图
利用纹理采样的得到`rgb`值，然后将`0~1`转化为`-1~1`
最后归一化即可得到`normalN`进行使用
```glsl
uniform sampler2D normalMapSampler;
void main()
{
	...
	//计算光照的通用数据
	//vec3 normalN = normalize(normal);
	vec3 normalN = texture(normalMapSampler, uv).rgb;
	normalN = normalN * 2.0 - vec3(1.0);//从0~1变成-1~1
	normalN = normalize(normalN);
	
	vec3 viewDir = normalize(worldPosition - cameraPosition);

	result += calculateDirectionalLight(objectColor, directionalLight,normalN, viewDir);
	...
}
```
### 1.3renderer中修改（pickShader，renderObject）
在`render.h`中声明一个`shader`对象
```cpp
private:
	...
	Shader* mPhongNormalShader{ nullptr };
```
到`render.cpp`中进行初始化
```cpp
Renderer::Renderer() {
	...
	mPhongNormalShader = new Shader("assets/shaders/advanced/phongNormal.vert", "assets/shaders/advanced/phongNormal.frag");
}
```
到`pickShader`方法中完善
```cpp
Shader* Renderer::pickShader(MaterialType type) {
	Shader* result = nullptr;

	switch (type) {
		...
	case MaterialType::PhongNormalMaterial:
		result = mPhongNormalShader;
		break;
	...
	}
	return result;
}
```
最后去到`renderObject`方法中添加相应的`case`
和`phongMaterial`没有什么区别，只是要多传输一个法线贴图
```cpp
case MaterialType::PhongNormalMaterial: {
	PhongNormalMaterial* phongMat = (PhongNormalMaterial*)material;

	//diffuse贴图帧更新
	//将纹理采样器与纹理单元进行挂钩
	shader->setInt("sampler", 0);
	//将纹理与纹理单元进行挂钩
	phongMat->mDiffuse->bind();
	
	//法线贴图
	shader->setInt("normalMapSampler", 1);
	phongMat->mNormalMap->bind();
	...
}
	break;
```

## 2.创建一个平面，使用法线贴图纹理
创建一个平面，
我们还是采用双`pass`渲染
```cpp
void prepare() {
	...
	//pass 01
	auto planeGeo = Geometry::createPlane(5, 5);
	auto planeMat = new PhongNormalMaterial();
	planeMat->mDiffuse = new Texture("assets/textures/normal/brickwall.jpg", 0, GL_SRGB_ALPHA);
	planeMat->mNormalMap = new Texture("assets/textures/normal/normal_map.png", 1);
	planeMat->mShiness = 32; //光斑大小
	auto planeMesh = new Mesh(planeGeo, planeMat);
	sceneOff->addChild(planeMesh);

	//pass 02
	auto sgeo = Geometry::createScreenPlane();
	auto smat = new ScreenMaterial();
	smat->mScreenTexture = fbo->mColorAttachment;
	//smat->mScreenTexture = new Texture("assets/textures/wall.jpg", 0, GL_SRGB_ALPHA);
	auto smesh = new Mesh(sgeo, smat);
	scene->addChild(smesh);
	...
}
```
用上法线贴图后真实了很多

![输入图片说明](/imgs/2025-02-20/gNADZ2bXwwC0CNpf.png)

我们做一个实验，现在的平面是朝向`+z`轴的，我们的法线贴图也是朝向`+z`轴的，现在把平面放倒朝向`+y`轴，平行光也调整过来直射`-y`方向
运行会发现黑不拉几的

![输入图片说明](/imgs/2025-02-20/ID06XQjrdqfhKr7j.png)

# TBN
## TBN向量空间介绍

![输入图片说明](/imgs/2025-02-20/e1rym9JyiOARUogc.png)

![输入图片说明](/imgs/2025-02-20/pp0qragApJbbKHXB.png)

其实就是法线的坐标通过`TBN`表示出来，
然后我们只需要求的`T`和`B`就可以把法线坐标转化到世界坐标系下，`N`其实就是三角形面片的三个点的法线向量相加除`3`
法线的世界坐标 = `TBN`组成的矩阵 * `n`（`n`是法线在`TBN`坐标系下的坐标）
`TBN`组成的矩阵可以通过由`T`，`B`，`N`三个列向量组成矩阵得到
## TBN向量计算方法
解释一下这个示例图，我们构建的`TB`坐标系，不是随便构建的，比如`u1`是`0.6`，那么在T方向上u1作垂线就得在`60%`上，其他坐标同理

![输入图片说明](/imgs/2025-02-20/CIvwfmz2hlfMdFyW.png)

![输入图片说明](/imgs/2025-02-20/AWyL45zitN3Dwy6d.png)

此时我们就把`TB`矩阵表示出来了，所以重点就是等式左边那坨怎么求
`E`的部分很好求，其实就是两个坐标相减得出的向量
所以`E1 = (u2, v2) - (u1, v1)`
所以现在主要工作在于求逆矩阵

![输入图片说明](/imgs/2025-02-20/fH6uiaStGj2TXb3L.png)

![输入图片说明](/imgs/2025-02-20/B49hR8NEOfgjQ1hY.png)

![输入图片说明](/imgs/2025-02-20/g1Q3ajh5OijkoqzY.png)

![输入图片说明](/imgs/2025-02-20/effPECC4unYRfaDD.png)

`T`要乘上`ModelMatrix`是因为当模型变换时`T`也要跟随变换，
而`N`不能直接乘`ModelMatrix`是因为，我们之前有做过，当一个球体比如沿着`x`缩小时，`N`并不会保持垂直缩小，所以我们要专门计算一个`NormalMatrix`（以前推到过）
最后`B`当然就可以直接通过`TN`的叉乘得到
通过以上计算就可以得到`TBN`矩阵
 
 ## 构建TBN矩阵实验（简单情况）
 ### 1.Geometry类，加入带tangent（切线）的构造函数（tangent作为顶点属性）
 在`geometry.h`中加入`mTangentVbo`以及一个带`tangent`的构造函数
```cpp
private:
	GLuint mTangentVbo{ 0 };

public:
	Geometry(
	const std::vector<float>& positions,
	const std::vector<float>& normals,
	const std::vector<float>& uvs,
	const std::vector<unsigned int>& indices,
	const std::vector<float>& tangents
);
```
在`geometry.cpp`中实现如下，其他的都和原来一样，只是加入了关于`mTangentVbo`的创建以及有关`vao`的使用
解释一下这里的`&`符号：`&` 用于避免复制数据，并且提高效率，`const` 确保数据在函数中是只读的。
好处是：
**性能**：避免了复制大数据结构（如向量）的开销。
**内存效率**：不需要创建数据的副本，节省内存。
```cpp
Geometry::Geometry(
	const std::vector<float>& positions,
	const std::vector<float>& normals,
	const std::vector<float>& uvs,
	const std::vector<unsigned int>& indices,
	const std::vector<float>& tangents
) {
	...
	glGenBuffers(1, &mTangentVbo);
	glBindBuffer(GL_ARRAY_BUFFER, mTangentVbo);
	glBufferData(GL_ARRAY_BUFFER, tangents.size() * sizeof(float), tangents.data(), GL_STATIC_DRAW);
	...

	glBindBuffer(GL_ARRAY_ BUFFER, mTangentVbo);
	glEnableVertexAttribArray(3);
	glVertexAttribPointer(3, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 3, (void*)0);
	...
}
```

 ### 2.修改PhongNormalShader，加入tangent相关计算
 ![输入图片说明](/imgs/2025-02-20/sv0j4mJOcf3smk5T.png)

先明确，我们现在构造的是简单几何的情况，比如平面的每一个点的法线的朝向都是一样的，
但是球体就不一样了，球体的顶点的法线方向会受到和它连接的三角面片的影响，是所有和它连接的三角面片共同作用影响的

所以我们这次制作简单情况的话，即平面的情况
那么它的`n`就是`normal =  normalMatrix * aNormal;`
然后`tangent`（`T`）又与`normal`（`N`）垂直，可以通过叉乘算出`bitangent`（也就是`B`）
但是这里问题来了，`normalMatrix * aNormal`没问题
但是`modelMatrix * aTangent`就有问题了，因为`aTangent`是三维向量，`modelMatrix`是四维矩阵。
把`modelMatrix`降维即可：`mat3(modelMatrix)`
因为我们原本把`TBN`做成三维就是因为它不用考虑平移情况，而`modelMatrix`第四维的情况就是用来处理平移的，所以直接降维不管即可

所以在`phongNormal.vert`做如下修改
```glsl
...
layout (location = 2) in vec3 aNormal;
layout (location = 3) in vec3 aTangent;

...
out mat3 tbn;
...
void main()
{
	...
	normal =  normalMatrix * aNormal;
	vec3 tangent = normalize(mat3(modelMatrix) * aTangent);
	vec3 bitangent = normalize(cross(normal, tangent));
	tbn = mat3(tangent, bitangent, normal);
}
```
所以这样我们就算出来`tbn`矩阵了，准备传给`frag`处理
去到`phongNormal.vert`做如下修改
通过`in mat3 tbn`接收到`vert`传过来的矩阵，
将`normalN = normalize(tbn * normalN)`我们就可以得到世界坐标系下的法线了
```glsl
...
in mat3 tbn;
...
void main()
{
//环境光计算
	...
	vec3 normalN = texture(normalMapSampler, uv).rgb;
	normalN = normalN * 2.0 - vec3(1.0);//从0~1变成-1~1
	normalN = normalize(tbn * normalN);
	...
}
```
 ### 3.prepare函数中，准备实验数据与环境
 我们以前使用`geometry`直接生成一个几何体，但是这样我们拿不到里面的顶点啊什么的七七八八的数据。
 所以我们临时在`prepare`中创建一个几何体用来实验
 解释一下下面的，`positions`，`uvs`，`normals`，`indices`都没啥好奇怪的，正常声明，声明完的平面长这样（自己盘一下坐标就明白了）：
 
![输入图片说明](/imgs/2025-02-20/TzI3cJPAwg5vtyEp.png)
 
 然后下面的tangent计算，是根据公式：
 
![输入图片说明](/imgs/2025-02-20/wUvv2iMGsYQm2KRk.png)

我们只关心`T`，`B`不管
计算完`T`之后用数组存储，然后调用我们先前设计的带有`tangent`参数的`geometry`构造函数
```cpp
 void prepare() {
		...

	//pass 01
	float halfW = 2.5f, halfH = 3.5f;
	std::vector<float> positions = {
		-halfW, -halfH, 0.0f,
		halfW, -halfH, 0.0f,
		halfW, halfH, 0.0f,
		-halfW, halfH, 0.0f,
	};

	std::vector<float> uvs = {
		0.0f, 0.0f,
		1.0f, 0.0f,
		1.0f, 1.0f,
		0.0f, 1.0f
	};

	std::vector<float> normals = {
		0.0f, 0.0f, 1.0f,
		0.0f, 0.0f, 1.0f,
		0.0f, 0.0f, 1.0f,
		0.0f, 0.0f, 1.0f,
	};

	std::vector<unsigned int> indices = {
		0, 1, 2,
		2, 3, 0
	};

	//计算tangents
	std::vector<float> tangents = {};
	//位置
	glm::vec3 pos1(positions[0], positions[1], positions[2]);
	glm::vec3 pos2(positions[3], positions[4], positions[5]);
	glm::vec3 pos3(positions[6], positions[7], positions[8]);
	//uv
	glm::vec2 uv1(uvs[0], uvs[1]);
	glm::vec2 uv2(uvs[2], uvs[3]);
	glm::vec2 uv3(uvs[4], uvs[5]);

	glm::vec3 e1 = pos2 - pos1;
	glm::vec3 e2 = pos3 - pos2;

	glm::vec2 dUV1 = uv2 - uv1;
	glm::vec2 dUV2 = uv3 - uv2;

	float f = 1.0f / (dUV1.x * dUV2.y - dUV2.x * dUV1.y);

	glm::vec3 tangent;
	tangent.x = f * (dUV2.y * e1.x - dUV1.y * e2.x);
	tangent.y = f * (dUV2.y * e1.y - dUV1.y * e2.y);
	tangent.z = f * (dUV2.y * e1.z - dUV1.y * e2.z);

	for (int i = 0; i < 4; i++) {
		tangents.push_back(tangent.x);
		tangents.push_back(tangent.y);
		tangents.push_back(tangent.z);
	}

	auto planeGeo = new Geometry(positions, normals, uvs, indices, tangents);
	auto planeMat = new PhongNormalMaterial();
	planeMat->mDiffuse = new Texture("assets/textures/normal/brickwall.jpg", 0, GL_SRGB_ALPHA);
	planeMat->mNormalMap = new Texture("assets/textures/normal/normal_map.png", 1);
	planeMat->mShiness = 32;
	auto mesh = new Mesh(planeGeo, planeMat);
	mesh->rotateX(-90.0f);
	sceneOff->addChild(mesh);
	...
	dirLight->mDirection = glm::vec3(0.0f, -1.0f, 0.0f);
	...

}
```
然后我们把平面旋转，平行光也旋转一下，发现没有问题，很完美

![输入图片说明](/imgs/2025-02-20/9A01xC37jIqbYCUg.png)

## 构建TBN矩阵实验（复杂情况） 

理解一下对于复杂几何体的情况
例如下图这种几何体，在顶点上的法向量`N`，会被它周围几个平面共同作用影响，所以就不会完全垂直于哪一个平面，
**`N`不会完全垂直于哪一个平面**！所以就会引入切线由于`N`不垂直，不垂直我们就不发构建坐标系了
 
![输入图片说明](/imgs/2025-02-23/3o9vHZCdIhqDInb0.png)

此时我们要对切线`T`进行妥协，调整`T`到与`N`垂直，即正交化
所以此时正交化得到的`T`**确实就不是原平面真正的切线**了

![输入图片说明](/imgs/2025-02-23/h6QRC78ARtu5v72U.png)

而对于几个不同平面共享的一个顶点，我们会有好几个不同的切线`T`（因为有好几个平面嘛），而对于一个顶点我们肯定只要一个`T`值进计算，
所以我们可以先将几个共享面的`T`值分别算出来，注意此时的算出来就已经包括了**正交化**这个步骤，将不同面的`T`值相加求和最后归一化
几个垂直于`N`的向量相加最后归一，得到的向量最终还是会垂直于`N`的

![输入图片说明](/imgs/2025-02-23/rjXfWbJwJywdaAC0.png)

## 1.Geometry类，加入球体针对每个三角形的切线计算
准备工作
去到`geometry.cpp`中，在`createSphere`函数中加入关于切线的逻辑
由于我们已经知道要存入多少数据进`tangents`中，一个顶点一个切线，一个切线用`xyz`三维向量表示
所以为了避免每次添加都要重新开辟数组空间（因为我们声明的`tangents`是空的），
所以我们直接使用`tangents.resize(positions.size())`进行数组大小声明，这句话的意思就是在`tangents`数组中放入全是`0`的元素，大小和`positions`一样（因为`positions`也是一个顶点一个位置，然后一个位置用三维向量表示，所以他们大小是一样的）
```cpp
std::vector<GLfloat> tangents{};
tangents.resize(positions.size());
```
总的代码如下：
```cpp
Geometry* Geometry::createSphere(float radius) {
	...
	std::vector<GLfloat> tangents{};
	...
	//开始计算切线
	tangents.resize(positions.size());

	//以三角形为单位进行indices的遍历
	for (int i = 0; i < indices.size(); i += 3) {
		//1 取出当前三角形的三个顶点的索引
		int idx0 = indices[i];
		int idx1 = indices[i + 1];
		int idx2 = indices[i + 2];

		//2 根据三个顶点的索引，从positions数组中找到三个顶点的位置信息
		auto p0 = glm::vec3(positions[idx0 * 3], positions[idx0 * 3 + 1], positions[idx0 * 3 + 2]);
		auto p1 = glm::vec3(positions[idx1 * 3], positions[idx1 * 3 + 1], positions[idx1 * 3 + 2]);
		auto p2 = glm::vec3(positions[idx2 * 3], positions[idx2 * 3 + 1], positions[idx2 * 3 + 2]);
		//3 根据三个顶点的索引，从uvs数组中找到三个顶点的uv信息
		auto uv0 = glm::vec2(uvs[idx0 * 2], uvs[idx0 * 2 + 1]);
		auto uv1 = glm::vec2(uvs[idx1 * 2], uvs[idx1 * 2 + 1]);
		auto uv2 = glm::vec2(uvs[idx2 * 2], uvs[idx2 * 2 + 1]);
		//4 根据公式，计算呢当前三角形的tangent
		glm::vec3 e0 = p1 - p0;
		glm::vec3 e1 = p2 - p1;

		glm::vec2 duv0 = uv1 - uv0;
		glm::vec2 duv1 = uv2 - uv1;

		float f = 1.0f / (duv0.x * duv1.y - duv1.x * duv0.y);

		glm::vec3 tangent;
		tangent.x = f * (duv1.y * e0.x - duv0.y * e1.x);
		tangent.y = f * (duv1.y * e0.y - duv0.y * e1.y);
		tangent.z = f * (duv1.y * e0.z - duv0.y * e1.z);
		tangent = glm::normalize(tangent);

		//5 针对本三角形的三个顶点的normal，使tangent正交化（三个不同的tangent）
		auto normal0 = glm::normalize(glm::vec3(normals[idx0 * 3], normals[idx0 * 3 + 1], normals[idx0 * 3 + 2]));
		auto normal1 = glm::normalize(glm::vec3(normals[idx1 * 3], normals[idx1 * 3 + 1], normals[idx1 * 3 + 2]));
		auto normal2 = glm::normalize(glm::vec3(normals[idx2 * 3], normals[idx2 * 3 + 1], normals[idx2 * 3 + 2]));

		auto tangent0 = tangent - glm::dot(tangent, normal0) * normal0;
		auto tangent1 = tangent - glm::dot(tangent, normal1) * normal1;
		auto tangent2 = tangent - glm::dot(tangent, normal2) * normal2;

		//6 累加到每个顶点的tangent属性上
		tangents[idx0 * 3] += tangent0.x;
		tangents[idx0 * 3 + 1] += tangent0.y;
		tangents[idx0 * 3 + 2] += tangent0.z;

		tangents[idx1 * 3] += tangent1.x;
		tangents[idx1 * 3 + 1] += tangent1.y;
		tangents[idx1 * 3 + 2] += tangent1.z;

		tangents[idx2 * 3] += tangent2.x;
		tangents[idx2 * 3 + 1] += tangent2.y;
		tangents[idx2 * 3 + 2] += tangent2.z;
	}

	//7 对每个顶点的最终tangent（累加值）进行normalize
	for (int i = 0; i < tangents.size(); i += 3) {
		glm::vec3 tangent = glm::vec3(tangents[i], tangents[i + 1], tangents[i + 2]);
		tangent = glm::normalize(tangent);
		tangents[i] = tangent.x;
		tangents[i + 1] = tangent.y;
		tangents[i + 2] = tangent.z;
	}

	//4 生成vbo与vao
	...

	glBindBuffer(GL_ARRAY_BUFFER, tangentVbo);
	glEnableVertexAttribArray(3);
	glVertexAttribPointer(3, 3, GL_FLOAT, GL_FALSE, sizeof(float) * 3, (void*)0);
	 
	...
}
```

## 2.实验
```cpp
void prepare() {
	...
	//pass 01
	auto geo = Geometry::createSphere(2);
	auto mat = new PhongNormalMaterial();
	mat->mDiffuse = new Texture("assets/textures/normal/brickwall.jpg", 0, GL_SRGB_ALPHA);
	mat->mNormalMap = new Texture("assets/textures/normal/normal_map.png", 1);
	mat->mShiness = 32;
	auto mesh = new Mesh(geo, mat);
	sceneOff->addChild(mesh);

	//pass 02
	auto sgeo = Geometry::createScreenPlane();
	auto smat = new ScreenMaterial();
	smat->mScreenTexture = fbo->mColorAttachment;
	//smat->mScreenTexture = new Texture("assets/textures/wall.jpg", 0, GL_SRGB_ALPHA);
	auto smesh = new Mesh(sgeo, smat);
	scene->addChild(smesh);
	...

}
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTIzMDIwNDQxMSwzMjQ2ODIyNTIsMTUwOT
IyODY0MywyMTgzMzU5NTAsMTM1MDU2OTI1NSwyMDY2OTI0ODU4
LDE3ODM2NzI1OTcsMjEzODk1ODQ3LDIxMDYwMzQ2MDUsMTMyMz
k5ODk0MCwtMTMyNDYxMDMwNCwxMDg5MDU0MjYzLC0xNDUyNTEw
NjU0LDEzMjU1NjczMDgsLTE3ODgyMzg2NSwxNTk0ODA1MTcsLT
EyNzY5ODgxNTEsLTUyMDQ4Mzk2LDE1NjIxNzI5NDIsLTY4MDY2
ODM4MF19
-->