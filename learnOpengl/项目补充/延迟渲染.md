# 理论设计
前向渲染是：**每渲染一个物体 → 计算完整光照 → 输出颜色**
延迟渲染是：

1.  第一步（GBuffer Pass）：渲染所有物体，把几何信息写入多个缓冲（GBuffer）：
    位置 / 法线 / 漫反射颜色 / 镜面反射参数 等
        
2.  第二步（Lighting Pass）：遍历光源，**在屏幕空间**中进行光照计算，生成最终颜色

开始设计
在原本前向渲染的基础上，我们需要
# 改造流程
## 1. 创建 GBuffer 结构

需要创建多个 FBO 颜色附件（GBuffer）：
```cpp
// 创建 FBO
glGenFramebuffers(1, &gBufferFBO);
glBindFramebuffer(GL_FRAMEBUFFER, gBufferFBO);

// GBuffer 分量
- Albedo + Specular（RGBA）
- Normal（RGB 或编码成 2 分量）
- Position（或深度）

// 每个使用 glTexImage2D 创建并 attach 到 GL_COLOR_ATTACHMENTi
glFramebufferTexture2D(...);
```

可以解释一下这个多个颜色附件
### 为什么要多个 Color Attachment？

**延迟渲染核心思想是：先收集“材质 + 几何信息”，统一做光照**。

这些信息无法塞进一个颜色输出（Color Attachment），所以我们需要**多个颜色缓冲（GBuffer）**，每个用来存储不同的信息：

`GL_COLOR_ATTACHMENT0`：Albedo + Specular，表面颜色、材质参数

`GL_COLOR_ATTACHMENT1`：法线（Normal），光照方向计算

`GL_COLOR_ATTACHMENT2`：世界坐标 / 视空间位置，计算光照方向、距离衰减

`GL_DEPTH_ATTACHMENT`：深度值，光照计算时还原位置 / 屏幕空间裁剪

👉 所以：
> “法线”、“UV”、“颜色”等都被**输出到不同的颜色 attachment 中”，放在同一个 FBO 里。

### 是不是多个 FBO？答案是 ❌ **一个 FBO + 多个 Color Attachment**

你只需要一个 FBO，但绑定多个纹理：
```cpp
glGenFramebuffers(1, &gBufferFBO);
glBindFramebuffer(GL_FRAMEBUFFER, gBufferFBO);

// 创建多个颜色 attachment 纹理
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, ..., gAlbedoTexture);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, ..., gNormalTexture);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, ..., gPositionTexture);

// 深度缓冲
glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, ..., depthBuffer);

// 告诉 OpenGL 你会写入这几个颜色附件
GLenum attachments[3] = {
  GL_COLOR_ATTACHMENT0,
  GL_COLOR_ATTACHMENT1,
  GL_COLOR_ATTACHMENT2
};
glDrawBuffers(3, attachments);
```
所以：
-   **一个 FBO**：整合多个 attachment
-   **多个 Attachment（GBuffer）**：用于 Geometry Pass 时输出多个数据通道
-   **每个 GBuffer 是一个贴图（Texture）**，之后 Lighting Pass 会用它们作为输入

## 2. 实现 Geometry Pass（写入 GBuffer）

-   使用一个新的 Shader（`geometry_pass.vert / frag`）
    
-   输出：
```cpp
out vec4 gAlbedoSpec;
out vec3 gNormal;
out vec3 gPosition;
```
不做光照计算，只写数据到多个目标

记得用：
```cpp
GLenum attachments[3] = {GL_COLOR_ATTACHMENT0, 1, 2};
glDrawBuffers(3, attachments);
```
这里是 **OpenGL 多重渲染目标（MRT，Multiple Render Targets）** 的关键设置
### 这段代码的作用：

它告诉 OpenGL：
> “当前绑定的 FBO 上，我要把 Fragment Shader 的多个输出写入哪些颜色附件（Color Attachment）。”
## 分解解释：

### 🔸 `GLenum attachments[3] = {GL_COLOR_ATTACHMENT0, 1, 2};`

这里定义了一个列表，表示我们准备“激活”哪些 `Color Attachment`（颜色输出槽）。

正确写法应该是：
```cpp
GLenum attachments[3] = {     
GL_COLOR_ATTACHMENT0,     
GL_COLOR_ATTACHMENT1,     
GL_COLOR_ATTACHMENT2 
};
```
### `glDrawBuffers(3, attachments);`

这句调用的含义是：

> “当前这个 FBO 中，我的 Fragment Shader 输出要写入这三个颜色目标。”

所以如果你在`fragment shader` 中这样写：
上面这个才是完整表达三个颜色目标：0、1、2。
```glsl
layout(location = 0) out vec4 gAlbedoSpec;
layout(location = 1) out vec3 gNormal;
layout(location = 2) out vec3 gPosition;
```
那么：

-   `gAlbedoSpec` → 写入 `GL_COLOR_ATTACHMENT0`
-   `gNormal` → 写入 `GL_COLOR_ATTACHMENT1`
-   `gPosition` → 写入 `GL_COLOR_ATTACHMENT2`

这样 GBuffer 的三个贴图就能一次性写完！
与**前向渲染**进行对比，为什么`fragment`还要`out`贴图出去？
### 前向渲染中：
`Fragment Shader` 是计算 **最终像素颜色**，所以你通常会看到：
```glsl
in vec3 normal; // 从 vertex shader 传入的插值数据
uniform vec3 lightDir;
out vec4 FragColor; // 最终颜色

void main() {
    float NdotL = max(dot(normal, lightDir), 0.0);
    FragColor = vec4(NdotL, NdotL, NdotL, 1.0); // 输出亮度
}
```
输出就是最终屏幕颜色，写入 color attachment 0。
### 延迟渲染中：
Fragment Shader 不再输出颜色结果，而是**“存储几何信息”**到多个缓冲中（GBuffer）：
```glsl
// 每个 out 对应一个颜色 attachment，写入贴图中
layout(location = 0) out vec4 gAlbedoSpec;
layout(location = 1) out vec3 gNormal;
layout(location = 2) out vec3 gPosition;

void main() {
    gAlbedoSpec = vec4(texture(diffuseMap, TexCoords).rgb, 1.0); // 材质颜色
    gNormal = normalize(Normal);       // 法线
    gPosition = FragPos;               // 世界坐标 or 视空间坐标
}
```
所以，
-   **这些 `out` 并不是最终颜色**
-   而是为了写入到你自己创建的 FBO 的 **多个贴图（color attachment）**
-   这些贴图将来会作为输入，传给下一个阶段（Lighting Pass）

**！！！注意**这个是`geometry`的`fragment shader`

### 为什么要这么设置？

因为 OpenGL 默认只写入 `GL_COLOR_ATTACHMENT0`，如果你要**启用多个输出**（比如延迟渲染的 GBuffer），就必须告诉 OpenGL：“我要写入多个 attachment”。

----------

### 类比理解：

你可以把它想象成：

> "我这个帧缓冲有好几个写入通道，告诉 OpenGL我想启用哪几个，并且 Shader 中的输出要怎么对号入座。"

## 3. 实现 Lighting Pass（光照计算）

-   使用一个全屏 Quad（或屏幕坐标三角形）
-   绑定上一步的 GBuffer 为贴图输入
-   对每个光源执行屏幕空间光照：

```cpp
vec3 albedo = texture(gAlbedo, uv).rgb;
vec3 normal = texture(gNormal, uv).xyz;
vec3 pos = texture(gPosition, uv).xyz;
vec3 lightDir = normalize(lightPos - pos);
vec3 diffuse = max(dot(normal, lightDir), 0.0) * lightColor * albedo;

```
## 4. 合成 Pass（Tone Mapping + Gamma + 后处理）

-   输出一个最终的颜色 FBO 结果
-   应用 Gamma 校正、Bloom 等后处理

## 5. 调整深度 & 管线控制

-   你需要合理管理 `depth buffer`，GBuffer Pass 写入 `depth`，Light Pass 不写
-   光照 Pass 中禁用深度写入：
```cpp
glDisable(GL_DEPTH_TEST);
glDepthMask(GL_FALSE);
```

# 总结
最后做一个设计总结，以`phong`为例
我们一共做了两套`shader`
### Geometry Pass（写 GBuffer）
-   `geometry.vert`
    -   把模型顶点从局部坐标变换到 clip space
    -   传出 world/eye 坐标、法线、UV
-   `geometry.frag`
   -   输出：
       位置（gPosition）
       法线（gNormal）
      漫反射颜色、镜面反射系数（gAlbedoSpec）

### Lighting Pass（计算光照）

-   `light.vert`
    -   通常渲染 `full-screen quad`，直接传屏幕坐标 `UV`
-   `light.frag`
    -   输入：`GBuffer` 中的贴图（gPosition, gNormal, gAlbedoSpec）
    -   按照 `Phong` 模型在屏幕空间中执行光照公式
    -   输出最终颜色


# 开始施工

## 完善shader
我们依据设计的原则，依次完善一下两套`shader`
`geometry.vert`
```glsl
#version 460 core
layout (location = 0) in vec3 aPos;
layout (location = 1) in vec2 aUV;
layout (location = 2) in vec3 aNormal;
layout (location = 3) in vec3 aTangent;

out vec2 uv;
out vec3 normal;
out vec3 worldPosition;
out mat3 tbn;

uniform mat4 modelMatrix;
uniform mat4 viewMatrix;
uniform mat4 projectionMatrix;

uniform mat3 normalMatrix;

//aPos作为attribute（属性）传入shader
//不允许更改的
void main()
{
// 将输入的顶点位置，转化为齐次坐标（3维-4维）
	vec4 transformPosition = vec4(aPos, 1.0);

	//做一个中间变量TransformPosition，用于计算四位位置与modelMatrix相乘的中间结果
	transformPosition = modelMatrix * transformPosition;

	//计算当前顶点的worldPosition，并且向后传输给FragmentShader
	worldPosition = transformPosition.xyz;

	gl_Position = projectionMatrix * viewMatrix * transformPosition;
	
	uv = aUV;
//	normal =  transpose(inverse(mat3(modelMatrix))) * aNormal;
	normal =  normalMatrix * aNormal;
	vec3 tangent = normalize(mat3(modelMatrix) * aTangent);
	vec3 bitangent = normalize(cross(normal, tangent));
	tbn = mat3(tangent, bitangent, normal);
}
```
`geometry.frag`
```glsl
#version 460 core

in vec2 uv;
in vec3 fragPos;
in mat3 tbn;

layout(location = 0) out vec4 gAlbedoSpec;  // RGB: albedo, A: metallic
layout(location = 1) out vec3 gNormal;
layout(location = 2) out vec3 gPosition;

uniform sampler2D albedoTex;
uniform sampler2D roughnessTex;
uniform sampler2D metallicTex;
uniform sampler2D normalTex;

void main()
{
	vec3 albedo = texture(albedoTex, uv).rgb;
	float metallic = texture(metallicTex, uv).b;

	vec3 N = texture(normalTex, uv).rgb;
	N = normalize(tbn * (N * 2.0 - 1.0));

	gPosition = fragPos;
	gNormal = N;
	gAlbedoSpec = vec4(albedo, metallic);
}

```
`light.vert`
```glsl
#version 460 core
layout (location = 0) in vec2 aPos;
out vec2 uv;

void main()
{
	uv = aPos * 0.5 + 0.5;
	gl_Position = vec4(aPos, 0.0, 1.0);
}

```
`light.frag`
```glsl
#version 460 core
out vec4 FragColor;

in vec2 uv;
in vec3 normal;
in vec3 worldPosition;
in mat3 tbn;

//相机世界位置
uniform vec3 cameraPosition;

#include "../../common/lightStruct.glsl"

uniform sampler2D albedoTex;//物体颜色(反照率）
uniform sampler2D roughnessTex;//粗糙度贴图
uniform sampler2D metallicTex;//金属度贴图
uniform sampler2D normalTex;//法线贴图

uniform PointLight pointLights[4];


#define PI 3.141592653589793

//NDF：α本应该表示粗糙度（roughness），α= r^2，便于美术调控
float NDF_GGX(vec3 N, vec3 H, float roughness){
	float a = roughness * roughness;
	float a2 = a*a;
	float NdotH = max(dot(N,H), 0.0);

	float num = a2;
	float denom =PI * (NdotH * NdotH *(a2 - 1.0) + 1.0);//分母

	denom = max(denom, 0.0001);//不能为0

	return num / denom;
}

//Geometry
float GeometrySchlickGGX(float NdotV, float roughness){
	float r = (roughness + 1.0);
	float k = r * r / 8.0;

	float num = NdotV;
	float denom = NdotV * (1.0 - k) + k;

	denom = max(denom, 0.00001);

	return num / denom;
}

//考虑几何遮蔽和几何阴影的共同作用得到的值
//此处的N是宏平面的法线方向
float GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness){
	float NdotV = max(dot(N,V),0.0);
	float NdotL = max(dot(N,L),0.0);

	float ggx1 = GeometrySchlickGGX(NdotV, roughness);
	float ggx2 = GeometrySchlickGGX(NdotL, roughness);

	return ggx1 * ggx2;
}

//Fresnel
vec3 fresnelSchlick(vec3 F0, float HdotV){
	return F0 + (1.0 - F0) * pow((1.0 - HdotV), 5.0);
}


void main()
{
	//1 准备通用数据
	vec3 albedo = texture(albedoTex, uv).xyz;
	//vec3 albedo = vec3(1.0, 0.0, 0.0);
	
	vec3 V = normalize(cameraPosition - worldPosition);

	vec3 N = texture(normalTex, uv).xyz;
	N = N * 2.0 - 1.0;
	N = normalize(tbn * N);

	float metallic = texture(metallicTex, uv).b;
	float roughness = texture(roughnessTex, uv).r;
	
	//2 计算基础反射率
	vec3 F0 = vec3(0.04);
	//因为金属颜色可以用自身的颜色表示，所以使用mix函数，metallic越大，表示金属度越高，自身颜色占的权重就更大
	F0 = mix(F0, albedo, metallic);

	//3 遍历四个点光源，计算反射总共的radiance
	vec3 Lo = vec3(0.0);
	for(int i = 0; i < 4; i++){
		//3.1 准备计算单个光源贡献的时候用到的通用数据
		vec3 L = normalize(pointLights[i].position - worldPosition);
		//半程向量H
		vec3 H = normalize(L + V);
		float NdotL = max(dot(N,L),0.0);
		float NdotV = max(dot(N,V),0.0);

		//3.2 计算光源打到平面上的irradiance
		float dis = length(pointLights[i].position - worldPosition);
		float attenuation = 1.0 / (dis * dis);
		vec3 irradiance = pointLights[i].color * NdotL * attenuation;

		//3.3 计算NDF G F各项值
		float D = NDF_GGX(N, H, roughness);
		float G = GeometrySmith(N, V, L, roughness);
		vec3 F = fresnelSchlick(F0, max(dot(H, V), 0.0));

		//3.4 决定diffuse与specular各自比例多少
		//因为F考虑的就是有多少光被反射出去了，所以用来做ks的权重刚刚好
		vec3 ks = F;
		vec3 kd = vec3(1.0) - ks;
		//考虑问题：对于金属而言是没有diffuse反射的！
		kd *= (1.0 - metallic);

		//3.5 计算cook-torrance BRDF的值
		vec3 num = D * G * F;//分子
		float denom = max(4.0 * NdotL * NdotV, 0.0000001);//分母，这里用max函数防止分母为0的情况
		vec3 specularBRDF = num / denom; 

		//3.6 考虑specular + diffuse最终的反射结果
		//此处specularBRDF不用再乘一次ks，因为num = D * G * F，以及考虑了F项，而F = ks
		Lo += (kd * albedo / PI + specularBRDF) * irradiance;
	}
	vec3 ambient = vec3(0.1) * albedo;
	Lo += ambient;

	FragColor = vec4(Lo, 1.0);
}
```

## 接下来创建对应的fbo
```cpp
Framebuffer* Framebuffer::createGBufferFbo(unsigned int width, unsigned int height)
{
	Framebuffer* fb = new Framebuffer();
	unsigned int fbo;
	glGenFramebuffers(1, &fbo);
	glBindFramebuffer(GL_FRAMEBUFFER, fbo);

	// 创建三个 G-Buffer 的 color attachment
	auto gPosition = Texture::createTexture(width, height, GL_RGB16F, GL_RGB, GL_FLOAT);
	auto gNormal = Texture::createTexture(width, height, GL_RGB16F, GL_RGB, GL_FLOAT);
	auto gAlbedoSpec = Texture::createTexture(width, height, GL_RGBA, GL_RGBA, GL_UNSIGNED_BYTE); // albedo.rgb + spec.a

	glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, gPosition->getTexture(), 0);
	glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT1, GL_TEXTURE_2D, gNormal->getTexture(), 0);
	glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT2, GL_TEXTURE_2D, gAlbedoSpec->getTexture(), 0);

	// 设置 draw buffer（重要）
	GLenum attachments[3] = {
		GL_COLOR_ATTACHMENT0,
		GL_COLOR_ATTACHMENT1,
		GL_COLOR_ATTACHMENT2
	};
	glDrawBuffers(3, attachments);

	// 添加深度缓冲
	auto rboDepth = Texture::createRenderBuffer(width, height, GL_DEPTH_COMPONENT);
	glFramebufferRenderbuffer(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_RENDERBUFFER, rboDepth->getTexture());

	// 检查完整性
	if (glCheckFramebufferStatus(GL_FRAMEBUFFER) != GL_FRAMEBUFFER_COMPLETE)
		std::cerr << "GBuffer Framebuffer not complete!" << std::endl;

	glBindFramebuffer(GL_FRAMEBUFFER, 0);

	fb->mFBO = fbo;
	fb->mGPosition = gPosition;
	fb->mGNormal = gNormal;
	fb->mGAlbedoSpec = gAlbedoSpec;
	fb->mDepthAttachment = rboDepth;
	fb->mWidth = width;
	fb->mHeight = height;

	return fb;
}
```
## 接下来创建texture
我们有深度`attachment`的创建方法
但是没有对应可以
```cpp
Texture* Texture::createTexture(
	unsigned int width,
	unsigned int height,
	unsigned int internalFormat, // 如 GL_RGB16F, GL_RGBA8
	unsigned int format,         // 如 GL_RGB, GL_RGBA
	unsigned int type,           // 如 GL_FLOAT, GL_UNSIGNED_BYTE
	unsigned int unit
) {
	Texture* tex = new Texture();
	tex->mWidth = width;
	tex->mHeight = height;
	tex->mUnit = unit;

	glGenTextures(1, &tex->mTexture);
	glActiveTexture(GL_TEXTURE0 + unit);
	glBindTexture(GL_TEXTURE_2D, tex->mTexture);

	glTexImage2D(GL_TEXTURE_2D, 0, internalFormat, width, height, 0, format, type, NULL);

	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST); // 避免 GBuffer 采样模糊
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);

	return tex;
}
```
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTU3MjA2OTQ4NSwxMzAzODY3NDc5LDYyNT
I4NzE4MSw0NDk5MDIyNjEsLTE3NjU0NDE3NTIsLTg1NzQ5ODg4
NCwtMTgyOTc0MjgxLDc2NzYzODIwNCw1MDM5NTk2MzFdfQ==
-->