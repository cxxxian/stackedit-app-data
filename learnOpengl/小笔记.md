# 有关于`fbo`和`viewport`的理解
我们在每一次准备渲染`fbo`时，都需要将`viewPort`调整到该`fbo`对应的大小
## 举例1
这是我们进行`bloom`渲染的时候，是将`src`提取高亮部分渲染到`dst`上，
我们在方法开头要将`viewPort`进行调整：`glViewport(0, 0, dst->mWidth, dst->mHeight);`
所以此处是对于`dst`的渲染，所以肯定要把`viewport`调整为`dst`的大小
```cpp
void Bloom::extractBright(Framebuffer* src, Framebuffer* dst)
{
	glBindFramebuffer(GL_FRAMEBUFFER, dst->mFBO);

	glViewport(0, 0, dst->mWidth, dst->mHeight);
	glClear(GL_COLOR_BUFFER_BIT);
	
	...
}
```

## 举例2
我们对于点光源的`mRenderTarget`也就是它的`fbo`设置为大小`1024, 1024`，意思就是我们`shadowMap`的大小到时候就是`1024 * 1024`
```cpp
PointLightShadow::PointLightShadow() {
	mCamera = new PerspectiveCamera(90.0f, 1.0, 0.1f, 50.0f);
	mRenderTarget = Framebuffer::createPointShadowFbo(1024, 1024);
}

```
这是我们`renderShadowMap`的方法，我们在渲染阴影贴图的时候，注意这时候我们先取到了目前`viewport`的大小，并进行了记录，其实这时候就记录的是我们当前的屏幕大小
然后我们就要把`viewport`改为和`shadowMap`大小对应的尺寸，再进行渲染
然后很重要的一步就是我们渲染完`shadowMap`之后，要把`viewport`的大小再改回屏幕大小
```cpp
void Renderer::renderShadowMap(
	Camera* camera,
	const std::vector<Mesh*>& meshes, 
	PointLight* pointLight) {
	...

	//2 保存原始状态，绘制shadowMap完毕后，要恢复原始状态
	GLint preFbo;
	glGetIntegerv(GL_FRAMEBUFFER_BINDING, &preFbo);

	GLint preViewport[4];
	glGetIntegerv(GL_VIEWPORT, preViewport);
	...

	glBindFramebuffer(GL_FRAMEBUFFER, pointShadow->mRenderTarget->mFBO);
	glViewport(0, 0, pointShadow->mRenderTarget->mWidth, pointShadow->mRenderTarget->mHeight);

	...

	glBindFramebuffer(GL_FRAMEBUFFER, preFbo);
	glViewport(preViewport[0], preViewport[1], preViewport[2], preViewport[3]);
}
```

# 向量指向问题
例如：
`worldPosition - cameraPosition`
是指`camera`位置指向物体`worldPosition`的向量

# 有关于texture和fbo的思考

![输入图片说明](/imgs/2025-02-12/7ntBrcUI7IdRxa42.png)

我们一开始声明附件对应`texture`的时候，一般最后都是填个`NULL`，说明最后并没有传输任何的数据进去
例如这个颜色`texture`附件
```cpp
Texture::Texture(unsigned int width, unsigned int height, unsigned int unit, unsigned int internalFormat) {
	mWidth = width;
	mHeight = height;
	mUnit = unit;

	glGenTextures(1, &mTexture);
	glActiveTexture(GL_TEXTURE0 + mUnit);
	glBindTexture(GL_TEXTURE_2D, mTexture);

	glTexImage2D(GL_TEXTURE_2D, 0, internalFormat, mWidth, mHeight, 0, GL_RGBA, GL_UNSIGNED_BYTE, NULL);

	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
	glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
}
```
那什么时候开始传输的
我们会将该附件绑定到`fbo`上，就像这样
```cpp
Framebuffer::Framebuffer(unsigned int width, unsigned int height) {
	...
	//2 生成颜色附件，并且加入fbo
	mColorAttachment = Texture::createColorAttachment(mWidth, mHeight, 0);
	glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0, GL_TEXTURE_2D, mColorAttachment->getTexture(), 0);

	//3 生成depth Stencil附件，加入fbo
	mDepthStencilAttachment = Texture::createDepthStencilAttachment(mWidth, mHeight, 0);
	glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_STENCIL_ATTACHMENT, GL_TEXTURE_2D, mDepthStencilAttachment->getTexture(), 0);

	...
}
```
此后我们在`main.cpp`进行渲染的时候，传入的是这个`fbo`的话，颜色和深度信息就会被赋值到这个贴图上了
```cpp
```cpp
int main() {
	...
	while (glApp->update()) {
		cameraControl->update();
		renderer->setClearColor(clearColor);
		//pass01
		renderer->render(sceneOffScreen, camera,dirLight, ambLight, fbo);
		//pass02
		renderer->render(sceneInScreen, camera, dirLight, ambLight);
		renderIMGUI();
	}

	glApp->destroy();

	return 0;
}
```
# 渲染技术
解耦其实就是通过多`pass`实现，利用`fbo`
## 一、前向渲染（Forward Rendering）流程
核心逻辑：逐物体 × 逐光源 计算光照
（复杂度 = 几何体数量 × 光源数量）
```
1. 遍历所有物体（Object）  
   |  
   v  
2. 对每个物体，遍历所有光源（Light）  
   |  
   v  
3. 在片段着色器中，同时计算几何数据（位置、法线）和光照  
   |  
   v  
4. 混合所有光源贡献，输出最终颜色到帧缓冲（直接写入屏幕）
```
关键问题：
重复计算几何数据：每个物体对每个光源都要重新计算顶点变换、法线、UV等。
过度绘制（Overdraw）：多个光源叠加时，同一像素可能被多次计算（尤其透明物体）。
无法高效剔除：无法快速判断哪些光源实际影响当前像素，必须遍历全部光源。
## 二、延迟渲染（Deferred Shading）流程
核心逻辑：解耦几何与光照
（复杂度 = 屏幕像素数 × 光源数量）

```
1. 几何阶段（Geometry Pass）  
   |  
   v  
   遍历所有物体 → 将几何数据（位置、法线、材质）写入 G-Buffer  
   （仅执行一次，不涉及光照）  
   |  
   v  
   G-Buffer 存储：位置、法线、漫反射颜色、金属度、粗糙度等...  

2. 光照阶段（Lighting Pass）  
   |  
   v  
   遍历所有像素（屏幕空间） → 从 G-Buffer 读取数据  
   |  
   v  
   遍历所有光源 → 仅计算影响当前像素的光源  
   |  
   v  
   混合所有光源贡献，输出最终颜色
```
关键优化：
几何数据只处理一次：无论有多少光源，几何阶段只执行一次。
按像素处理光源：每个像素独立判断受哪些光源影响（例如分块剔除）。
无过度绘制：光照阶段只处理可见像素（深度缓冲已确定）。

# TBDR
解析：TBDR架构如何优化延迟渲染的带宽消耗？
核心原理（比喻版）
想象你是一位画家，需要在画布上完成一幅复杂的油画。这幅画分为两步：第一步用铅笔勾勒所有物体的轮廓和细节（生成G-Buffer），第二步再为每个区域上色（计算光照）。

### 桌面端（非TBDR，如传统PC/Mac）：
工作流程：
你每次画一小块区域时，都需要跑到远处的仓库（系统内存）取铅笔稿（G-Buffer），上色后再跑回仓库存结果。
问题：频繁往返仓库消耗体力（带宽），但仓库足够大且搬运工具（显存带宽）高效，勉强能接受。
### 移动端（TBDR，如iOS设备）：
工作流程：
你先把整幅画分成多个小瓷砖（Tile），每块瓷砖的铅笔稿（G-Buffer）都暂时存放在手边的工具箱（On-Chip Memory）里。
上色阶段：直接在工具箱里完成这块瓷砖的所有上色操作，不需要跑仓库。
完成后：把上好色的瓷砖一次性搬回仓库（系统内存）。
优势：减少90%的跑腿次数（带宽消耗），省时省电。

#### 终极比喻：厨房做菜
非TBDR（桌面）：
你每次炒菜都要打开冰箱（系统内存）取食材（G-Buffer），用完再放回去。冰箱很大但开关门费电。
TBDR（iOS）：
你把食材按菜谱分装到小餐盒（Tile），全部放在料理台（On-Chip Memory）上。炒菜时直接从台上取，最后一次性收拾回冰箱。

# Early Z vs Depth PrePass

| 特性 | Early Z | Depth PrePass |
|--------------------|------------------------------|-------------------------------|
| 控制方 | GPU 硬件自动优化 | 开发者手动实现 |
| 执行阶段 | 片段着色器前 | 独立渲染阶段 |
| 优化范围 | 逐物体局部优化 | 全场景全局优化 |
| 适用场景 | 简单不透明物体 | 复杂遮挡场景、半透明物体 |
| 修改深度值影响 | 失效（回退到 Late Z）| 无影响（深度已预计算）|
| 带宽消耗  | 无额外消耗 | 需要额外写入深度缓冲区 |


将渲染管线比作战场清理：
Early Z 像士兵逐个房间搜索，发现敌人立即开火（局部高效但可能重复检查）
`Depth PrePass` 像先用热成像扫描整栋建筑，生成精确的敌人位置图，士兵按图精准清除（全局规划避免重复工作）
在复杂战场（场景）中，预先掌握全局信息（`Depth PrePass）的效率远高于依赖局部判断（Early Z）。
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTEyODg2ODI5NzQsMTQ5OTA0Mjc4OSwtOD
gxMDAzOTg0LC0xODE3MzQ5MjkyLC0xNzQ2NDUzNTE5LDY2OTA4
MjE3NiwxMjY0MTI5NTEwXX0=
-->