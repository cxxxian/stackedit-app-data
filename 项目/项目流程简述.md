## **整体流程**

### 1️⃣ 你有一个 **SplatMesh**

-   本质上是由大量高斯溅射点（position、scale、rotation、color 等属性）组成的点云状几何。
    
-   在 Spark 系统里，它是 `SplatGenerator` 的产物，可以直接被 SparkRenderer 接管。
    

----------

### 2️⃣ **SparkRenderer** 接管

-   把 SplatMesh 的数据打包成 `PackedSplats`（纹理/Buffer 格式，方便 GPU 读取）。
    
-   存进 `SplatAccumulator`，用于后续的渲染与排序。
    
-   绑定一个 ShaderMaterial（Spark 的 splat shader），替代普通 mesh 的材质。
    
-   SparkRenderer 自己其实就是一个 **Three.js 的 Mesh**，它有 geometry + material。
    

----------

### 3️⃣ **SparkViewpoint** 辅助排序

-   SparkViewpoint 不直接画图，而是：
    
    1.  根据当前相机矩阵计算每个 splat 的排序 metric（深度/径向距离）。
        
    2.  用 GPU shader（`computeVec4.glsl` 等）在 FBO 中生成 metric 数据。
        
    3.  CPU readback + 桶排序，生成绘制顺序 `ordering`。
        
-   排序结果传回 SparkRenderer 的 geometry index buffer，让 splats 按正确顺序绘制（透明度正确）。
    

----------

### 4️⃣ 渲染

-   在 Three.js 的渲染循环里，SparkRenderer（一个 mesh）就像普通物体一样被渲染。
    
-   Shader 内部会按 `ordering` 取数据并绘制每个 splat，最终出现在屏幕上。
    
-   如果是离屏渲染（比如 `prepareRenderPixels`），则是画到 FBO，再读回像素数据。
    

----------

## **一句话总结**

**SparkRenderer = 一个带特殊 shader 的 Mesh**，  
SparkViewpoint = **帮这个 Mesh 排好 splat 绘制顺序的助手**，  
最终 SparkRenderer 像普通 Mesh 一样进入 Three.js 场景被渲染。

<!--stackedit_data:
eyJoaXN0b3J5IjpbLTIwMTc4NDk0MjZdfQ==
-->