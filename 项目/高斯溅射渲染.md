
## 一、识别你的 PLY 格式类型

首先明确你的 `.ply` 是哪种格式：

1.  **Unpacked 格式**（每个 splat 显式记录属性，float 为主）
    
2.  **Packed 格式**（压缩编码后的，使用 chunk 分区和字节位操作）
    
3.  **SuperSplat 或其他自定义格式**
    

不同格式影响解析和上传到 GPU 的方式。

----------

## 二、基本流程概览

> 以下以 Three.js 或 WebGL 为例，也适用于原生 OpenGL / WebGPU。

### 1. **加载 `.ply` 文件并解析数据**

#### 解析步骤：

-   读取头部（Header）  
    判断属性类型，如：
    
```
property float x 
property float y 
property float z 
property float scale_0 
property float quaternion_0 
property uchar red ...
```
    
-   按数据格式（ASCII 或 binary）读取所有点（splat）属性：
    
    -   位置（x, y, z）
        
    -   方向（quaternion 或 covariance 矩阵）
        
    -   尺度（scale_x, scale_y, scale_z）
        
    -   颜色（RGB 或 RGBA）
        
    -   不确定性参数（log scale, alpha, etc）
        

> 如果是 packed 格式，你需要先“解码”为 float 格式，才能继续后续处理。

----------

### 2. **组织数据并上传到 GPU（构建 Buffer）**

把每个 splat 的属性整理成适合上传到 GPU 的结构，比如：

```
// 示例结构 [   
center.x, center.y, center.z,   
scale.x, scale.y, scale.z,   
quat.x, quat.y, quat.z, quat.w,   
r, g, b, a,   ... 
]
```

-   创建 `Float32Array` 或 `Uint8Array` 来存放这些数据。
    
-   使用 `THREE.BufferGeometry` 和 `BufferAttribute` 上传。
    

----------

### 3. **编写自定义着色器（Vertex + Fragment）**

#### 顶点着色器（Vertex Shader）

-   解析 splat 的属性（位置、缩放、方向、颜色等）
    
-   计算高斯投影到屏幕空间的椭圆参数（M matrix 或类似）
    
-   输出给片段着色器
    

#### 片段着色器（Fragment Shader）

-   对每个像素做透明融合（alpha blending）
    
-   基于高斯密度场叠加贡献（权重 + 颜色）
    

参考高斯 splatting 的论文中的屏幕空间融合公式。

----------

### 4. **混合设置与渲染控制**

-   启用透明混合：
    
```
gl.enable(gl.BLEND); 
gl.blendFunc(gl.ONE, gl.ONE); // 加权融合
```
    
-   控制 splat 数量（LOD、Chunk-based）
    
-   深度排序或前向累加（Depends on renderer）


## 为什么要对高斯体排序？

### **1. 为了正确的透明度渲染（Alpha Blending）**

高斯 splatting 通常使用 **加权颜色融合**（例如加权平均，OIT：Order Independent Transparency 的一种变体），但**如果使用标准 alpha blending（如 gl.ONE, gl.ONE_MINUS_SRC_ALPHA）时，顺序就很重要**。

#### 举例：

假如你从后往前画：

`背景 → 远处 splat → 近处 splat`

若顺序错了（先画近的再画远的），远处的 splat 会被不正确地遮挡或混合，产生：

-   颜色偏暗
    
-   亮度不真实
    
-   边缘断裂、错位感
    

🎯 **解决办法：按视点距离从远到近排序 splats**（Painter’s Algorithm）

----------

### **2. 支持逐步渲染或分块加载**

排序之后，可以：

-   **裁剪掉靠后的 splat**（提升性能）
    
-   **只渲染前 N 个最重要 splats**（例如在 LOD 中，按贡献度排序）
    

### **3. 实现正确的前向加权平均融合**

高斯渲染常用：

```
gl.blendFunc(gl.ONE, gl.ONE);
```

或者：

```
gl_FragColor.rgb += weight * color; 
gl_FragColor.a   += weight;
```
之后再 `normalize：`

```
finalColor = accum.rgb / accum.a;
```

虽然这种方式理论上**顺序无关（order independent）**，但如果你的 shader 计算中引入了非线性因素（例如：

-   **近大远小的 scale 映射**
    
-   **log-opacity 处理**
    
-   **early-Z discard**  
    ），就会出现实际效果依赖于渲染顺序。

# shader设计
顶点着色器（vertex shader）——核心任务：构建屏幕空间椭圆
```glsl
// 输入属性：每个 splat 一个点
in vec3 center;
in vec3 scale;
in vec4 quat;
in vec4 color;

uniform mat4 modelViewMatrix;
uniform mat4 projectionMatrix;

void main() {
    // 1. 计算 splat 中心的视图空间位置
    vec4 viewPos = modelViewMatrix * vec4(center, 1.0);

    // 2. 构建协方差矩阵 Sigma（高斯扩散）
    mat3 R = quaternionToRotationMatrix(quat);
    mat3 S = scaleMatrix(scale); // diagonal
    mat3 Sigma = R * S * transpose(R);

    // 3. 投影变换到屏幕空间
    mat3 J = computeJacobian(viewPos); // 投影Jacobian
    mat3 A = J * Sigma * transpose(J); // 屏幕空间协方差矩阵

    // 4. 输出顶点位置（屏幕中心）供 rasterizer 用
    gl_Position = projectionMatrix * viewPos;

    // 5. 把 A 矩阵传给 fragment（需要 flat varying 或 SSBO）
    out_mat3 A_screen = A;
    out_vec4 rgba = color;
}
```
```glsl
// Compute the 3D covariance matrix of the splat
mat3 RS = scaleQuaternionToMatrix(scales, viewQuaternion);
mat3 cov3D = RS * transpose(RS);
// Compute the Jacobian of the splat's projection at its center
vec2 scaledRenderSize = renderSize * focalAdjustment;
vec2 focal = 0.5 * scaledRenderSize * vec2(projectionMatrix[0][0], projectionMatrix[1][1]);
float invZ = 1.0 / viewCenter.z;
vec2 J1 = focal * invZ;
vec2 J2 = -(J1 * viewCenter.xy) * invZ;
mat3 J = mat3(
	J1.x, 0.0, J2.x,
	0.0, J1.y, J2.y,
	0.0, 0.0, 0.0
);
// Compute the 2D covariance by projecting the 3D covariance
// and picking out the XY plane components.
// Keeping below because we may need it in the future
// for skinning deformations.
// mat3 W = transpose(mat3(viewMatrix));
// mat3 T = W * J;
// mat3 cov2D = transpose(T) * cov3D * T;
mat3 cov2D = transpose(J) * cov3D * J;
float a = cov2D[0][0];
float d = cov2D[1][1];
float b = cov2D[0][1];
```
以上是完整的决定 3D 高斯椭球投影到屏幕后变成什么样的 2D 椭圆部分。
解释如下：
### 1.计算 3D 协方差矩阵

```glsl
mat3 RS = scaleQuaternionToMatrix(scales, viewQuaternion); 
mat3 cov3D = RS * transpose(RS);
```
`scaleQuaternionToMatrix(scales, viewQuaternion)`
    → 先旋转再缩放，把单位球形高斯变成一个有方向的椭球。
`RS * transpose(RS)`  
    → 数学上，协方差矩阵 Σ = R S² Rᵀ，这里 R 和 S 合在 `RS` 矩阵里，所以直接乘转置就得到 Σ。
    
这个 Σ（`cov3D`）是在**相机空间（view space）**下的 3D 高斯协方差矩阵。
### 2.构建投影的雅可比矩阵 `J`
```glsl
vec2 scaledRenderSize = renderSize * focalAdjustment;
vec2 focal = 0.5 * scaledRenderSize * vec2(projectionMatrix[0][0], projectionMatrix[1][1]);
float invZ = 1.0 / viewCenter.z;
vec2 J1 = focal * invZ;
vec2 J2 = -(J1 * viewCenter.xy) * invZ;
mat3 J = mat3(
    J1.x, 0.0, J2.x,
    0.0, J1.y, J2.y,
    0.0, 0.0, 0.0
);
```
这一段是关键，作用是：  
**求出在当前 splat 中心位置附近，3D 坐标的微小变化 dx、dy、dz 会如何变成屏幕上的 dx′、dy′**。
#### 逐行解释：

1.  **计算像素单位下的焦距向量**
    
```glsl
vec2 focal = 0.5 * scaledRenderSize * vec2(projectionMatrix[0][0], projectionMatrix[1][1]);
```
从投影矩阵中提取 `fx`、`fy`（相机的焦距），并按像素单位调整。
`projectionMatrix[0][0]` = fx / (屏幕宽的一半)  
`projectionMatrix[1][1]` = fy / (屏幕高的一半)
        
2.  **深度缩放**
```glsl
float invZ = 1.0 / viewCenter.z; 
vec2 J1 = focal * invZ;
```
透视投影下，物体越远（Z大）投影越小，所以这里用 `1/z` 缩放。
`J1` 表示 3D 空间中 X、Y 方向的变化对屏幕的直接缩放比例。
        
3.  **透视投影的 Z 依赖**
```glsl
vec2 J2 = -(J1 * viewCenter.xy) * invZ;
```
物体在 Z 方向的位移会让投影整体缩放，这一项就是对 Z 的偏导数部分。
`(J1 * viewCenter.xy)` → 当前点的 X、Y 距离光轴越远，Z 变化影响越大。
负号来自透视公式的分母。
        
4.  **组装雅可比矩阵**
```glsl
mat3 J = mat3(     
	J1.x, 0.0, J2.x,     
	0.0, J1.y, J2.y,     
	0.0, 0.0, 0.0 );
```
第一行 `(∂x′/∂X, ∂x′/∂Y, ∂x′/∂Z)`
第二行 `(∂y′/∂X, ∂y′/∂Y, ∂y′/∂Z)`
第三行没用到，因为我们只关心 2D 屏幕。

### 3. 用雅可比把 3D 协方差投影到 2D
```glsl
mat3 cov2D = transpose(J) * cov3D * J; 
float a = cov2D[0][0]; 
float d = cov2D[1][1]; 
float b = cov2D[0][1];
```
数学公式：

![输入图片说明](/imgs/2025-08-09/KE6E3gVgiA2XRCah.png)

`cov3D` 是相机空间下的椭球协方差
`J` 是投影雅可比矩阵
得到的 `cov2D` 就是屏幕空间（像素单位）的椭圆协方差矩阵
`a`, `d`, `b` 是协方差矩阵的分量

![输入图片说明](/imgs/2025-08-09/lR6EssSWQJ3M1BTO.png)

它决定了屏幕上椭圆的大小、长短轴方向、旋转角度。

### 4. 为什么这一段是重点
这是 **3D → 2D 高斯投影的核心数学变换**。
没有这个，屏幕上的 splat 就只能是固定大小的圆点，不能随着视角倾斜变形。
有了它，splat 才能：
正确透视缩放（近大远小）
倾斜成椭圆
精确计算每个像素的高斯密度

片段着色器（fragment shader）——核心任务：计算密度 + 融合颜色
```glsl
in mat3 A_screen; // 屏幕空间协方差矩阵
in vec4 rgba;

out vec4 outColor;

void main() {
    // 1. 当前像素相对椭圆中心的偏移（在 NDC 或屏幕空间中）
    vec2 delta = gl_FragCoord.xy - center_screen.xy;

    // 2. 计算高斯密度：ρ(x) = exp(-0.5 * x^T * A_inv * x)
    float density = exp(-0.5 * dot(delta, A_screen * delta));

    // 3. 混合输出
    vec3 rgb = rgba.rgb * density;
    float alpha = rgba.a * density;

    outColor = vec4(rgb, alpha);
}
```
**！！！**这里的`A_screen`是`Σ2D`的逆矩阵，很重要，根据概率密度函数来的

![输入图片说明](/imgs/2025-08-09/iwOA8qGh8DpWkIWu.png)

总结一下：
**1. 协方差矩阵在 3D 里干的事**

-   初始状态的高斯是一个**单位球形分布**（各个方向标准差相等）。
    
-   通过旋转矩阵 R 和缩放矩阵 S，你可以把这个球变成任意方向、任意长短轴的**3D 椭球**。
    
-   这个形状信息数学上就是 3D 协方差矩阵
    

公式：

![输入图片说明](/imgs/2025-08-09/HHCAToSb3rQGYVYL.png)

----------

**2. 雅可比矩阵干的事**

-   透视投影不是线性的，近大远小、倾斜变形，这些都是投影过程的非线性结果。
    
-   雅可比矩阵 J 描述了**在当前中心点附近，3D 的微小位移如何线性近似地映射到 2D 屏幕**。
    
-   用 J 把 3D 协方差“挤压”到屏幕上，就能得到**屏幕上的 2D 椭圆形状**。
    

公式：

![输入图片说明](/imgs/2025-08-09/4R5XH4BRZu5rr9VC.png)

完整公式如下：

`R`，`S`是旋转和缩放矩阵，求得协方差矩阵

![输入图片说明](/imgs/2025-08-09/TTG767QDenb8TDlY.png)

利用`W`视图变换矩阵转到相机空间下，和`J`雅可比矩阵，得到二维协方差矩阵，送到后面做颜色计算，利用高斯密度函数

![输入图片说明](/imgs/2025-08-09/WC69UYvCFy62EjJ5.png)

记得是`Σ’`的逆矩阵，很重要，根据概率密度函数来的

![输入图片说明](/imgs/2025-08-09/iwOA8qGh8DpWkIWu.png)


# `SparkRenderer.ts` 和 `SparkViewpoint.ts` 配合

### **SparkRenderer**（渲染管理器）

-   核心职责：
    收集场景里所有的 `SplatGenerator` 生成的高斯溅射数据（Gsplat）
	把这些数据打包成纹理 (`PackedSplats`) 并存放到 `SplatAccumulator`
	提供默认视角 `defaultView`，并维护多个 `SparkViewpoint`
	在渲染循环 (`onBeforeRender`) 中，根据相机位置更新数据、设置 shader uniforms
        
-   特点：
只管“**有哪些 splats、它们的数据怎么更新**”
不管“**这些 splats 从什么视角排序、怎么画出来**”，这交给 `SparkViewpoint`
----------

### **SparkViewpoint**（视角 + 排序 + 输出）

-   核心职责：
表示一个**独立的观察视角**（摄像机矩阵 `viewToWorld`）
根据该视角对 splats 排序（远到近），生成绘制索引 `ordering`
可以绑定一个离屏渲染目标（`target`）输出纹理
支持多种排序模式（radial、Z-depth、stochastic 等）
特点：
只管“**在这个相机视角下，splats 按什么顺序画**”
不直接更新 splats 数据，数据来源是 `SparkRenderer.active` 里的 `SplatAccumulator`

## **配合流程**

假设要从某个视角离屏渲染：

```
SparkViewpoint.prepareRenderPixels(scene, camera)
```

流程是：

1.  **SparkViewpoint.prepare(...)**
设置 `viewToWorld`（用传入的相机矩阵）
调 `SparkRenderer.updateInternal(...)`  
→ 让 `SparkRenderer` 生成或更新 `active` 的 splats 数据（`SplatAccumulator`）
调 `SparkViewpoint.sortUpdate(...)`  
→ 从 GPU 渲染出每个 splat 的深度值（float16/float32）  
→ 回读到 CPU  
→ 用 worker 做桶排序，得到 `ordering`  
→ 更新 `SplatGeometry`，绑定 splats 的绘制顺序
        
2.  **SparkViewpoint.renderTarget(...)**
把 SparkRenderer 的 `viewpoint` 暂时切到当前 `SparkViewpoint`
用 `renderer.render(scene, camera)` 把 splats 按刚才的排序画到 `target` 纹理
如果是双缓冲（`doubleBuffer`），会在渲染后 swap
        
3.  **SparkViewpoint.readTarget(...)**
调 `readRenderTargetPixelsAsync` 把离屏 FBO 的 RGBA 数据读成 `Uint8Array`
如果 `superXY>1`，会做 CPU 下采样
        
4.  返回像素数据

##  为什么会牵扯到fbo

牵涉到 FBO 主要是因为 **SparkViewpoint 里的排序**，  
不是为了正常把高斯溅射体画出来，而是为了**先用 GPU 计算排序所需的深度信息**。

----------

### 1. 如果只是直接画到场景
是的，最终的高斯溅射渲染确实是直接作为 Three.js 的一个 `Mesh`（`SparkRenderer`）画到场景里。
这种情况下，GPU 直接跑 splat shader → 输出到屏幕。
    
---------

### 2. 为什么还要 FBO

排序这一步没法直接从“渲染到屏幕”拿数据，因为它不是要画颜色，而是要从 GPU 拿每个 splat 的**深度值**。

#### 排序流程回顾

`SparkViewpoint.sortUpdate()` 里：

1.  调用 `reader.renderReadback(...)`  
    → 把排序 shader (`doubleSortReader` / `sort32Reader`) 运行一遍  
    → 输出的是编码了**深度值**（float16/float32）的 RGBA 像素数据
    
2.  这些像素数据必须通过 **`gl.readPixels`** 回到 CPU  
    → CPU 再用桶排序得到 `ordering`
    

而 `gl.readPixels` 只能从 **当前绑定的 framebuffer** 读，所以这里必须先把排序结果渲染到一个 FBO（离屏缓冲区）。

> 也就是说，这个 FBO 不是用来显示，而是 GPU→CPU 数据交换的临时容器。

----------

### 3. 正常渲染 vs 排序用渲染

-   **正常渲染**（SparkRenderer.onBeforeRender → ShaderMaterial）  
    → 直接渲染 splats 到屏幕，FBO 不参与
    
-   **排序用渲染**（SparkViewpoint.sortUpdate）  
    → 渲染到 FBO（offscreen target）  
    → `gl.readPixels` 把深度值读回 CPU  
    → 排好顺序再进行正常渲染
    

----------

### 4. 为什么不能直接 CPU 算深度

理论上 CPU 也能用 `viewMatrix * position` 算深度，但：

-   splats 数据可能是 packed 在 GPU buffer/texture 里的
    
-   CPU 解包和矩阵运算会很慢（几十万~几百万 splats）
    
-   GPU 一次 draw call 就能并行算完，而且能直接把结果放到显存 → readback
    
所以它用 GPU 来算 metric（radial/Z-depth），FBO 只是 GPU→CPU 的桥梁。

### 总结：

核心就是 **通过 FBO 把 GPU 计算结果存成纹理（或 renderbuffer）再用 `gl.readPixels` 读回 CPU**，  
不过这里不是直接读“深度缓冲”，而是**自己在 shader 里算排序用的深度值（或距离 metric）并写进颜色缓冲**。

### 1. 为什么不用直接读 GPU 的 depth buffer

-   WebGL（尤其是 WebGL1/2）不支持直接高效地读 depth buffer，而且深度值的格式可能是非线性、受投影矩阵影响的。
    
-   排序用的不一定是标准 OpenGL depth（0~1），它可能是：
    
    -   **Z-depth + bias**
        
    -   **radial distance**
        
    -   甚至是双精度打包成两个半精度（float16）
        
-   所以 SparkViewpoint 用了一个**自定义的排序 shader**（`doubleSortReader` / `sort32Reader`），  
    在 fragment shader 里直接输出这个 metric 到颜色通道（RGBA8）。

### 2. GPU → CPU 具体流程

#### （1）创建 FBO

```js
const target = new THREE.WebGLRenderTarget(width, height, {   
format: THREE.RGBAFormat,   
type: THREE.UnsignedByteType, 
});
```

这其实就是一个带颜色附件的 framebuffer，可以被 `gl.readPixels` 读。
#### （2）用排序 shader 渲染

-   顶点着色器：根据 splat index 从 `PackedSplats` 里取中心点、旋转、scale…
    
-   片元着色器：计算排序 metric（radial distance 或 z-depth bias）
    
-   把这个 metric **编码成 RGBA**：
    
    -   float32 → `uintBitsToFloat` → `uintToRgba8`
        
    -   两个 float16 → `packHalf2x16` → `uintToRgba8`
        
-   输出到 FBO 的颜色缓冲

#### （3）读回数据
```js
const pixels = new Uint8Array(width * height * 4);
gl.readPixels(
  0, 0, width, height,
  gl.RGBA, gl.UNSIGNED_BYTE,
  pixels
);
```
这样 `pixels` 就是 GPU shader 输出的 RGBA8 数据。
#### （4）CPU 解码

-   如果是 float16 打包：  
    两个半精度合成一个 32 位整数，再转成 JS 浮点数
    
-   如果是 float32：  
    直接按 IEEE754 解码
    
----------

#### （5）CPU 排序

-   用桶排序（counting sort）按 metric 从大到小排 splat 索引
    
-   得到 `ordering` 数组
    
-   把 `ordering` 传回渲染管线，让正常的 splat shader 按顺序绘制
    

----------

### 3. 重点

-   **FBO 只是 GPU→CPU 的中转容器**
    
-   真正的排序数据（metric）不是 GPU 原生深度缓冲，而是**自定义计算的 float 值**
    
-   这种方法在 WebGL 环境下是最稳妥的，因为**读 color buffer 比读 depth buffer 可控**，而且格式可自定义
<!--stackedit_data:
eyJoaXN0b3J5IjpbNzM5ODM2MTcsLTE0MjM5Mzg5NDMsLTIyMT
E5OTM4OCw5NzY1MzY2NDRdfQ==
-->