# 数据类型占用
-   `short`：2 字节（16 位）
    
-   `int`：4 字节（32 位）
    
-   `float`：4 字节（32 位，IEEE 754 单精度浮点数）
    
-   `double`：8 字节（64 位，IEEE 754 双精度浮点数）
    
-   `char`：1 字节（8 位）

-   `long` 是 4 字节（32 位）
    
-   `long long` 是 8 字节（64 位）
    
-   指针（如 `int*`, `void*` 等）：8 字节（64 位系统下，指针大小通常是 8 字节；在 32 位系统下是 4 字节）

# 内存对齐规则（padding填充）
## 结构体内存对齐的基本规则

### 1. 每个成员的 **地址偏移** 必须是其类型的对齐要求的倍数

-   `char` 对齐到 1 字节
    
-   `int` 对齐到 4 字节
    
-   `double` 对齐到 8 字节
    
-   指针在 64 位系统上通常对齐到 8 字节
    

**结构体在排布成员时，会自动填充 padding 来满足这些对齐要求。**

### 2. 整个结构体的大小（`sizeof(struct)`）必须是**最大对齐量的整数倍**

-   最大对齐量 = 结构体中最大对齐需求的成员的对齐数
    

否则编译器可能会在结构体结尾加尾部 padding。

## Padding 发生的三种情况

### 1. **成员之间的 padding**

当前成员的结尾 **不足以对齐下一个成员**，就会填充。

例如：
```cpp
struct A {
    char c;     // 1 byte
    int i;      // 4 bytes, but必须4字节对齐 ⇒ 填充3字节
};
```
-   实际排布是：`[c][padding(3)][i]` ⇒ `sizeof(A) = 8`

### 2. **结构体结尾的 padding**

结构体整体大小必须是 **最大成员对齐数的倍数**，否则在结尾再加 padding。

例如：

```cpp
struct B {
    int i;      // 4 bytes
    char c;     // 1 byte
    // padding 3 bytes at end to align to 4
};

```
sizeof(B) = 8

### 3. **嵌套结构体的 padding**

结构体内嵌一个结构体，也要保证子结构体正确对齐。
```cpp
struct Inner {
    char c;
    int i;
}; // sizeof(Inner) = 8

struct Outer {
    double d;
    Inner in;
}; // 由于 Inner 首地址必须按其最大对齐（4）对齐，d 结束后可能填 padding。
```
## 小技巧：如何手动减少 padding？

1.  **将成员从大到小排列**（按对齐需求从大到小）  
    避免小成员把大成员“卡”在中间，需要填充。
    
2.  **使用 `#pragma pack` 或 `alignas()` 控制对齐**（慎用）  
    会影响 ABI，可能带来跨平台 bug。
    
3.  **考虑缓存行对齐**（性能优化）

# 为什么要进行内存对齐
## 1. 硬件访问效率：**未对齐访问更慢，甚至不允许**

-   大多数 CPU（尤其是 x86, ARM）访问数据时，希望变量的地址是 **对齐的**。
    
    -   例如：访问 4 字节的 `int`，地址要是 4 的倍数（如 `0x1004`、`0x1008`）
        
    -   访问 8 字节的 `double`，地址要是 8 的倍数
        

> 否则 CPU 需要 **额外的总线周期** 来读取跨越多个内存单元的数据，甚至在某些架构（比如老的 ARM）会直接报错（"unaligned access"）。

## 2. CPU 指令集要求

-   有些 CPU 不支持“未对齐访问”，对齐是**硬性要求**。
    
-   不对齐会导致：
    
    -   程序崩溃（访问异常）
        
    -   性能大幅下降
        

例如：
```cpp
struct A {
    char c;     // 1 byte
    int i;      // 4 bytes, 要求4字节对齐
};

```
若 `i` 没有对齐到4的倍数地址，某些平台上会直接 **崩溃或抛异常**。

## 3. 内存对齐让访问更**高效**

-   CPU从内存中取数据是按 **块** 取的（通常为4字节或8字节）
    
-   如果变量不对齐，CPU就要做**两次读取+拼接**，效率更低
    
对齐好的内存访问可以：
-   更快的载入寄存器
-   减少总线访问次数
-   提高缓存友好度（cache line）

## 总结一句话：

> **内存对齐是为了让 CPU 更快、更安全、更高效地访问内存，避免性能损失和平台兼容问题。**

### 解释一下如果变量不对齐，CPU就要做两次读取+拼接，效率更低

这句话的意思是：**如果一个变量在内存中没有按照它所需的对齐方式对齐，CPU 就不能一次性地完整读取它，只能分两次从内存中取数据，然后手动拼接成最终值，这样开销就大了。**

我们来一步一步解释这个过程：
### 前提：CPU 访问内存通常是**以对齐块读取**

现代 CPU 从内存读取数据时，是按**固定大小的内存块（一般是 4 字节或 8 字节）**读取的，比如：

-   一个 4 字节的 `int` 通常要求 **地址是 4 的倍数**
    
-   一个 8 字节的 `double` 通常要求 **地址是 8 的倍数**
    

这些“对齐”的地址，能让 CPU 一次从 **一个内存总线周期中读取完整数据**。
**举例**：
你要读取一个 4 字节的 `int`，但它存放在偏移 `101` 的位置，也就是跨越了两个 4 字节对齐的内存块（100–103 和 104–107）：

-   前 3 字节在第一个块：`101`~`103`
-   第 1 字节在下一个块：`104`

### 结果：
-   CPU 无法用一次操作取到完整 4 字节
    
-   需要：
    
    1.  读取前一个内存块（100–103）
    2.  再读取下一个内存块（104–107）
    3.  把两个结果拼起来，才拿到完整的变量值

## 简单讲一下为什么CPU拆分块进行读取
### **速度快（硬件优化）**

CPU 与内存之间通过 **总线** 传输数据，这些总线本身是 **一次传输一整块（如 4 字节、8 字节、64 字节）** 的。

-   就像高速公路：一趟运一车货（整块），比你反复单字节搬更快
    
-   统一块大小可以极大简化硬件逻辑 → 加速取数
### **更高效的缓存系统（cache）**

CPU 有 L1/L2/L3 缓存，按 **cache line（常为 64 字节）** 为单位存储数据。

-   你一访问变量，CPU 会把整块（包含变量的附近数据）一起读进 cache
    
-   所以**你接下来访问附近变量就更快了**（空间局部性原理）

### **简化硬件电路设计**

-   对齐访问 ⇒ 读一次 ⇒ 存进寄存器 ⇒ 直接使用
    
-   不对齐访问 ⇒ 要“跨块”，还要拼接、掩码、移位 ⇒ 硬件更复杂、速度更慢
    

> 所以**为了统一硬件行为**，内存访问尽可能都要求“整块且对齐”。

# placement new 
`placement new `是 C++ 中一种特殊形式的 `new` 表达式，它允许你**在一块已经分配好的内存上**构造对象，而不是像普通 `new` 那样自动分配内存。
简单来说：**placement new** 就是 “在指定地址上调用构造函数”。

### 语法格式：
```cpp
new (address) Type(arguments);
```
-   `address`：已经准备好的一块内存（必须足够大，且满足对齐要求）
-   `Type(arguments)`：在该内存上构造一个 `Type` 类型的对象

举个例子：
```cpp
#include <new>     // 必须包含这个头文件
#include <iostream>

struct MyClass {
    int x;
    MyClass(int v) : x(v) { std::cout << "Ctor: " << x << '\n'; }
    ~MyClass()              { std::cout << "Dtor: " << x << '\n'; }
};

int main() {
    // 1. 手动申请原始内存
    void* buffer = std::malloc(sizeof(MyClass));

    // 2. 在该内存上构造对象（不会再申请内存）
    MyClass* obj = new (buffer) MyClass(42);  // placement new

    // 3. 使用对象
    std::cout << "Value: " << obj->x << '\n';

    // 4. 手动析构 + 释放内存
    obj->~MyClass();
    std::free(buffer);

    return 0;
}
```

# 内存状态：reserved，commited，free

## 内存的三种状态
`Free`
没有使用的虚拟地址空间
无真正占用物理内存

`Reserved`
保留了一段地址空间，但**还没分配物理内存页**
无真正占用物理内存，只是保证别人不能用这段地址

`Committed`
地址空间已映射到物理内存或页面文件
✅ 占用物理内存或页面文件

## 三种状态的转换
1. `malloc` 本质上申请的是 `Committed` 内存

2. 手动管理时可能用 `Reserved` → `Committed`
对于高级程序员或系统程序员（如内存池、自定义分配器开发者），可以这么操作：
```cpp
void* addr = VirtualAlloc(nullptr, size, MEM_RESERVE, PAGE_READWRITE);
// 此时只是预留了地址空间（reserve），还没有物理内存

VirtualAlloc(addr, size, MEM_COMMIT, PAGE_READWRITE);
// 现在才真正为那块地址分配物理页（commit）
```
你可以先 reserve 一整块大内存，然后按需 commit 一部分（节省资源）

### 举个形象类比

-   **Free**：空地，谁都可以来建房
-   **Reserved**：我圈了一块地，标记为“保留”，别人不能建，但我还没建
-   **Committed**：我正式建好了房子（房子 = 物理内存页）

### 那 `malloc` 是什么时候 commit 的？

大多数 malloc 库（如 glibc malloc, Windows CRT malloc）：
-   会从系统中申请 **一个大块 committed 内存**
-   然后在自己的堆中进行切割，管理分配给用户
-   当堆空间耗尽时，才会再次向操作系统申请更多 committed 内存

**所以你用 `malloc` 时看到的是一次成功分配，其实背后早就 commit 好一整块或多块内存了**

### 总结

malloc 会保留还是 commit？
直接 commit（可能通过内存池或系统 API）

reserve 是什么时候用的？
高级分配器 / 自定义内存管理中，为预留地址空间用

为什么区分这几种状态？
允许更高效地管理内存资源（尤其大内存、多进程等场景）

是谁标记这些状态的？
操作系统内核维护虚拟内存页表，在调用如 `VirtualAlloc` 时标记
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTMzMTYyOTgzMSw1ODk2MDQ3MTEsLTc5Nj
gzODg0LDYyMjY4MTc4NiwtMTUzMTgwNDE2OSwxMzA2OTAzMDc0
LDg2NDcyNDkxMywxMzA4NTU5NDFdfQ==
-->