# c++多线程
`join`
加入主线程，使得主线程强制等待该线程执行完。
`detach`
从主线程分离，使得主线程无需等待该线程执行完。
`swap`
与另外一个线程交换线程对象。
`joinable`
查询是否可加入主线程。
`get_id`
获取该线程的唯一标识符。
`native_handle`
返回实现层的线程句柄。
`hardware_concurrency`
静态接口，返回硬件支持的并发线程数量。


使用范例：

```c++
#include <iostream>
#include <thread>
#include <chrono>

void foo()
{
    // simulate expensive operation
    std::this_thread::sleep_for(std::chrono::seconds(1));
}
 
int main()
{
    std::cout << "starting thread...\n";
    std::thread t(foo); // 构造线程对象，且传入被执行的函数。
 
    std::cout << "waiting for thread to finish..." << std::endl;
    t.join(); // 加入主线程，使得主线程必须等待该线程执行完毕。
 
    std::cout << "done!\n";
}
```
简单来说就是将子线程加入主线程，然后主线程必须等待该线程执行完毕

输出：

```cpp
starting thread...
waiting for thread to finish...
done!
```

如果需要在调用线程和新线程之间同步数据，则可以使用C++的`std::promise`和`std::future`等机制。
示例代码：

```c++
#include <vector>
#include <thread>
#include <future>
#include <numeric>
#include <iostream>
 
void accumulate(std::vector<int>::iterator first,
                std::vector<int>::iterator last,
                std::promise<int> accumulate_promise)
{
    int sum = std::accumulate(first, last, 0);
    accumulate_promise.set_value(sum);  // Notify future
}
 
int main()
{
    // Demonstrate using promise<int> to transmit a result between threads.
    std::vector<int> numbers = { 1, 2, 3, 4, 5, 6 };
    std::promise<int> accumulate_promise;
    std::future<int> accumulate_future = accumulate_promise.get_future();
    std::thread work_thread(accumulate, numbers.begin(), numbers.end(),
                            std::move(accumulate_promise));
 
    // future::get() will wait until the future has a valid result and retrieves it.
    // Calling wait() before get() is not needed
    //accumulate_future.wait();  // wait for result
    std::cout << "result = " << accumulate_future.get() << '\n';
    work_thread.join();  // wait for thread completion
}
```
和`join`的一个很明显的区别就是，`promise`和`future`配合可以返回结果，`join`不行

输出结果：
```ini
result = 21
```

如果需要强制异步，则可使用`std::async`。它可以指定两种异步方式：`std::launch::async`和`std::launch::deferred`，前者表示使用新的线程异步地执行任务，后者表示在当前线程执行，且会被延迟执行。使用范例：

```c++
#include <iostream>
#include <vector>
#include <algorithm>
#include <numeric>
#include <future>
#include <string>
#include <mutex>
 
std::mutex m;
struct X {
    void foo(int i, const std::string& str) {
        std::lock_guard<std::mutex> lk(m);
        std::cout << str << ' ' << i << '\n';
    }
    void bar(const std::string& str) {
        std::lock_guard<std::mutex> lk(m);
        std::cout << str << '\n';
    }
    int operator()(int i) {
        std::lock_guard<std::mutex> lk(m);
        std::cout << i << '\n';
        return i + 10;
    }
};
 
template <typename RandomIt>
int parallel_sum(RandomIt beg, RandomIt end)
{
    auto len = end - beg;
    if (len < 1000)
        return std::accumulate(beg, end, 0);
 
    RandomIt mid = beg + len/2;
    auto handle = std::async(std::launch::async,
                             parallel_sum<RandomIt>, mid, end);
    int sum = parallel_sum(beg, mid);
    return sum + handle.get();
}
 
int main()
{
    std::vector<int> v(10000, 1);
    std::cout << "The sum is " << parallel_sum(v.begin(), v.end()) << '\n';
 
    X x;
    // Calls (&x)->foo(42, "Hello") with default policy:
    // may print "Hello 42" concurrently or defer execution
    auto a1 = std::async(&X::foo, &x, 42, "Hello");
    // Calls x.bar("world!") with deferred policy
    // prints "world!" when a2.get() or a2.wait() is called
    auto a2 = std::async(std::launch::deferred, &X::bar, x, "world!");
    // Calls X()(43); with async policy
    // prints "43" concurrently
    auto a3 = std::async(std::launch::async, X(), 43);
    a2.wait();                     // prints "world!"
    std::cout << a3.get() << '\n'; // prints "53"
} // if a1 is not done at this point, destructor of a1 prints "Hello 42" here
```
看看英语注释其实就明白了
分别分为默认，延迟，立即三种策略
默认即无特别标注类型
延迟：`std::launch::deferred`
立即：`launch::async`

执行结果：

```python
The sum is 10000
43
Hello 42
world!
53
```

## **C++多线程同步**
线程同步的机制有很多，C++支持的有以下几种：

### std::atomic

`is_lock_free`：检查原子对象是否无锁的。

`store`：存储值到原子对象。

`load`：从原子对象加载值。

`exchange`：获取原子对象的值，并替换成指定值。

`compare_exchange_weak, compare_exchange_strong`：将原子对象的值和预期值（expected）对比，如果相同就替换成目标值（desired），并返回`true`；如果不同，就加载原子对象的值到预期值（expected），并返回`false`。weak模式不会卡调用线程，strong模式会卡住调用线程，直到原子对象的值和预期值（expected）相同。

`fetch_add, fetch_sub, fetch_and, fetch_or, fetch_xor`：获取原子对象的值，并对其相加、相减等操作。

`operator ++, operator --, operator +=, operator -=, ...`：对原子对象响应各类操作符，操作符的意义和普通变量一致。

利用`compare_exchange_weak`接口可以很方便地实现线程安全的非阻塞式的数据结构。示例：

```c++
#include <atomic>
#include <future>
#include <iostream>

template<typename T>
struct node
{
    T data;
    node* next;
    node(const T& data) : data(data), next(nullptr) {}
};
 
template<typename T>
class stack
{
 public:
    std::atomic<node<T>*> head;    // 堆栈头, 采用原子操作.
 public:
    // 入栈操作
    void push(const T& data)
    {
        node<T>* new_node = new node<T>(data);
 
        // 将原有的头指针作为新节点的下一节点.
        new_node->next = head.load(std::memory_order_relaxed);
 
        // 将新的节点和老的头部节点做对比测试, 如果new_node->next==head, 说明其它线程没有修改head, 可以将head替换成new_node, 从而完成push操作.
        // 反之, 如果new_node->next!=head, 说明其它线程修改了head, 将其它线程修改的head保存到new_node->next, 继续循环检测.
        while(!head.compare_exchange_weak(new_node->next, new_node,
                                        std::memory_order_release,
                                        std::memory_order_relaxed))
            ; // 空循环体
    }
};

int main()
{
    stack<int> s;
    
    auto r1 = std::async(std::launch::async, &stack<int>::push, &s, 1);
    auto r2 = std::async(std::launch::async, &stack<int>::push, &s, 2);
    auto r3 = std::async(std::launch::async, &stack<int>::push, &s, 3);
    
    r1.wait();
    r2.wait();
    r3.wait();
    
    // print the stack's values
    node<int>* node = s.head.load(std::memory_order_relaxed);
    while(node)
    {
        std::cout << node->data << " ";
        node = node->next;
    }
}
```

输出：

```basic
2 3 1
```

解释一下：
`node`就是一个结构体，保存一个值 `data` 和一个指向下一个节点的指针 `next`。是一个典型的单向链表结构。
无锁栈 `stack` 的实现：
```cpp
template<typename T>
class stack {
public:
    std::atomic<node<T>*> head;
```
`head` 是一个原子指针，指向栈顶节点（链表头部），用于在多线程下安全地操作。
```cpp
void push(const T& data)
{
    node<T>* new_node = new node<T>(data);

    new_node->next = head.load(std::memory_order_relaxed);

    while(!head.compare_exchange_weak(new_node->next, new_node,
                                      std::memory_order_release,
                                      std::memory_order_relaxed))
        ;
}
```
这个 `push` 实现了**无锁并发入栈**，其核心思想是 CAS（Compare-And-Swap，比较并交换）：

1.  分配一个新节点 `new_node`，将它的 `next` 指针指向当前的栈顶 `head`。
    
2.  使用 `compare_exchange_weak`：
    
    -   如果 `new_node->next == head`，表示这期间没有其他线程更改 `head`，则把 `head` 设置为 `new_node`，表示入栈成功。
        
    -   否则表示 `head` 已被其他线程更改，那么更新 `new_node->next` 为当前最新的 `head`，重试入栈。
        
3.  这个循环持续直到 CAS 成功，完成无锁入栈。


<!--stackedit_data:
eyJoaXN0b3J5IjpbMTc4NDgwMDQxMiwtMTU1MDEwNTkyNiwtMT
Q1ODU1ODg3OCwtNzQxMzczMTU3LDg3NjgxMjA4NF19
-->